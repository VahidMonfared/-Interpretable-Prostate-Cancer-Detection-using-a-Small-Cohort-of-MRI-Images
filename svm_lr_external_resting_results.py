# -*- coding: utf-8 -*-
"""SVM LR External resting results

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15oi51AKh_qhsEGsvQ-bLIGKBjbU7ucaD
"""





# ============================================================
# FAST External Validation (slice-level) on Prostate158 TEST
# - Works with state_dict checkpoints (your .pt files)
# - Robust lesion-mask detection (by sparsity), not by filename
# - Slice-level metrics: AUC, Accuracy, Sensitivity, Specificity, F1
# ============================================================

import os, re, zipfile, subprocess, sys, random, warnings
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

warnings.filterwarnings("ignore")
SEED = 42
random.seed(SEED)

# -------------------------
# CONFIG
# -------------------------
DATA_ROOT   = Path("/content/prostate158_test")
ZIP_PATH    = DATA_ROOT / "prostate158_test.zip"
EXTRACT_DIR = DATA_ROOT / "extracted"
ZENODO_URL  = "https://zenodo.org/records/6592345/files/prostate158_test.zip?download=1"

# speed controls
MAX_CASES = 20                 # set None for all
POS_SLICES_PER_CASE = 4
NEG_SLICES_PER_CASE = 4
IMG_SIZE = 224
BATCH = 16

# mask heuristics (safe defaults)
MASK_UNIQUE_MAX = 32
LESION_FRAC_MAX = 0.03         # lesion masks are usually very sparse
MASK_FRAC_MAX   = 0.80         # ignore all-ones weird volumes

# Your state_dict checkpoint paths (already in /content/)
MODEL_PATHS = {
    "resnet18": "/content/prostate_resnet18_bestfold.pt",
    "vit":      "/content/prostate_vit_bestfold.pt",
    "swin_cam": "/content/swin_bestfold_cam.pt",
}

# -------------------------
# install deps
# -------------------------
def pip_install(pkgs):
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q"] + pkgs)

pip_install(["SimpleITK", "scikit-learn", "timm", "torchvision"])

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as tvm
import timm
import SimpleITK as sitk

from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, f1_score, roc_curve

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# -------------------------
# download + unzip (if needed)
# -------------------------
DATA_ROOT.mkdir(parents=True, exist_ok=True)
if not ZIP_PATH.exists():
    print("Downloading prostate158_test.zip (~203MB)...")
    subprocess.check_call(["wget", "-O", str(ZIP_PATH), ZENODO_URL])
else:
    print("Found zip:", ZIP_PATH)

if not EXTRACT_DIR.exists():
    print("Unzipping...")
    EXTRACT_DIR.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(ZIP_PATH, "r") as zf:
        zf.extractall(EXTRACT_DIR)
else:
    print("Already unzipped:", EXTRACT_DIR)

# -------------------------
# IO helpers
# -------------------------
def is_volume(p: Path) -> bool:
    n = p.name.lower()
    return p.is_file() and (n.endswith(".mha") or n.endswith(".nii") or n.endswith(".nii.gz"))

def read_vol(path: Path) -> np.ndarray:
    img = sitk.ReadImage(str(path))
    arr = sitk.GetArrayFromImage(img)  # (z,y,x)
    return arr.astype(np.float32)

def safe_norm01(img2d: np.ndarray) -> np.ndarray:
    x = img2d.astype(np.float32)
    p1, p99 = np.percentile(x, 1), np.percentile(x, 99)
    if p99 <= p1 + 1e-6:
        mn, mx = float(x.min()), float(x.max())
        if mx <= mn + 1e-6:
            return np.zeros_like(x, dtype=np.float32)
        x = (x - mn) / (mx - mn)
        return np.clip(x, 0, 1)
    x = np.clip(x, p1, p99)
    x = (x - p1) / (p99 - p1)
    return np.clip(x, 0, 1)

def to_tensor_rgb(img01: np.ndarray, out_size=224) -> torch.Tensor:
    # img01: [H,W] float in [0,1] -> [3,out,out]
    t = torch.from_numpy(img01).unsqueeze(0).unsqueeze(0)  # [1,1,H,W]
    t = t.repeat(1,3,1,1)  # [1,3,H,W]
    t = F.interpolate(t, size=(out_size,out_size), mode="bilinear", align_corners=False)
    # ImageNet normalization
    mean = torch.tensor([0.485,0.456,0.406]).view(1,3,1,1)
    std  = torch.tensor([0.229,0.224,0.225]).view(1,3,1,1)
    t = (t - mean) / std
    return t.squeeze(0)

# -------------------------
# state_dict loading helpers
# -------------------------
def strip_module(sd: Dict[str, Any]) -> Dict[str, Any]:
    return { (k[7:] if k.startswith("module.") else k): v for k,v in sd.items() }

def load_state_dict_any(path: str) -> Dict[str, Any]:
    ckpt = torch.load(path, map_location="cpu")
    if isinstance(ckpt, dict):
        for key in ["state_dict", "model_state_dict", "model", "net", "weights"]:
            if key in ckpt and isinstance(ckpt[key], dict):
                return strip_module(ckpt[key])
        # assume dict itself is a state_dict
        return strip_module(ckpt)
    raise ValueError(f"Checkpoint format not supported: {type(ckpt)}")

# -------------------------
# model definitions (binary)
# -------------------------
def build_resnet18_binary(drop=0.35):
    m = tvm.resnet18(weights=None)
    in_f = m.fc.in_features
    m.fc = nn.Sequential(nn.Dropout(drop), nn.Linear(in_f, 1))
    return m

class ViTBinary(nn.Module):
    def __init__(self, backbone="vit_base_patch16_224", drop=0.35):
        super().__init__()
        self.backbone = timm.create_model(backbone, pretrained=False, num_classes=0)
        d = self.backbone.num_features
        self.head = nn.Sequential(nn.Dropout(drop), nn.Linear(d, 1))
    def forward(self, x):
        emb = self.backbone(x)
        logits = self.head(emb)
        return logits

class SwinBinaryCAM(nn.Module):
    def __init__(self, backbone="swin_base_patch4_window7_224", out_index=3, drop=0.35):
        super().__init__()
        self.backbone = timm.create_model(backbone, pretrained=False, features_only=True, out_indices=(out_index,))
        with torch.no_grad():
            dummy = torch.zeros(1,3,IMG_SIZE,IMG_SIZE)
            feat = self.backbone(dummy)[0]
            c = feat.shape[1]
        self.pool = nn.AdaptiveAvgPool2d((1,1))
        self.head = nn.Sequential(nn.Dropout(drop), nn.Linear(c, 1))
    def forward(self, x):
        feat = self.backbone(x)[0]
        emb = self.pool(feat).flatten(1)
        logits = self.head(emb)
        return logits

def load_model(name: str, path: str) -> nn.Module:
    if not os.path.exists(path):
        raise FileNotFoundError(f"Missing model checkpoint: {path}")
    if name == "resnet18":
        model = build_resnet18_binary()
    elif name == "vit":
        model = ViTBinary()
    elif name == "swin_cam":
        model = SwinBinaryCAM()
    else:
        raise ValueError("Unknown model: " + name)

    sd = load_state_dict_any(path)
    missing, unexpected = model.load_state_dict(sd, strict=False)
    print(f"[{name}] loaded state_dict: {path}")
    if missing: print(f"  missing keys: {len(missing)} (ok)")
    if unexpected: print(f"  unexpected keys: {len(unexpected)} (ok)")
    return model.to(device).eval()

models = {k: load_model(k,v) for k,v in MODEL_PATHS.items()}

# -------------------------
# Case discovery:
# - case folder = folder containing a T2 file
# - pick T2 by filename (best effort)
# - pick lesion mask by scanning other volumes for sparse mask-like arrays
# -------------------------
def looks_like_t2(p: Path) -> bool:
    n = p.name.lower()
    if "t2" not in n and "t2w" not in n:
        return False
    # avoid ADC/DWI
    bad = any(k in n for k in ["adc","dwi","hbv","ktrans","bval","bvalue"])
    # avoid obvious masks
    if any(k in n for k in ["mask","seg","label","anno","annot"]):
        return False
    return not bad

def mask_likeness(arr: np.ndarray) -> Optional[Tuple[float,int]]:
    if arr.size == 0: return None
    flat = arr.ravel()
    # sample for uniqueness
    if flat.size > 200_000:
        idx = np.random.choice(flat.size, 200_000, replace=False)
        samp = flat[idx]
    else:
        samp = flat
    uniq = np.unique(samp)
    uq = int(uniq.size)
    if uq > MASK_UNIQUE_MAX:
        return None
    nz = int(np.count_nonzero(arr))
    frac = float(nz) / float(arr.size)
    if frac <= 0.0 or frac >= MASK_FRAC_MAX:
        return None
    return (frac, uq)

def pick_lesion_mask(folder: Path, t2_path: Path) -> Optional[Path]:
    vols = [p for p in folder.iterdir() if is_volume(p)]
    others = [p for p in vols if p.resolve() != t2_path.resolve()]
    if not others:
        return None

    scored = []
    for p in others:
        try:
            a = read_vol(p)
            sc = mask_likeness(a)
            if sc is None:
                continue
            frac, uq = sc
            scored.append((frac, uq, p))
        except Exception:
            continue

    if not scored:
        return None

    # choose the sparsest mask-like volume under lesion threshold
    lesion_like = [x for x in scored if x[0] < LESION_FRAC_MAX]
    if lesion_like:
        lesion_like.sort(key=lambda x: x[0])
        return lesion_like[0][2]
    return None

# folders that contain at least one T2 candidate
all_vols = [p for p in EXTRACT_DIR.rglob("*") if is_volume(p)]
t2_files = [p for p in all_vols if looks_like_t2(p)]
case_folders = sorted({p.parent for p in t2_files})

print(f"Detected case folders: {len(case_folders)}")
if MAX_CASES is not None:
    case_folders = case_folders[:MAX_CASES]
print(f"Cases to evaluate: {len(case_folders)}")

# -------------------------
# Build slice dataset (within-case positives & negatives)
# label slice = 1 if lesion mask has any pixels on that slice
# -------------------------
X_list, y_list, case_ids = [], [], []
used_cases = 0

for ci, folder in enumerate(case_folders):
    vols = [p for p in folder.iterdir() if is_volume(p)]
    t2_candidates = [p for p in vols if looks_like_t2(p)]
    if not t2_candidates:
        continue
    # pick shortest name as a stable preference
    t2_path = sorted(t2_candidates, key=lambda x: len(x.name))[0]

    mask_path = pick_lesion_mask(folder, t2_path)
    if mask_path is None:
        continue

    try:
        vol = read_vol(t2_path)
        msk = read_vol(mask_path)
    except Exception:
        continue

    if vol.ndim != 3 or msk.ndim != 3 or vol.shape != msk.shape:
        continue

    pos_slices = np.where(np.sum(msk > 0, axis=(1,2)) > 0)[0].tolist()
    neg_slices = np.where(np.sum(msk > 0, axis=(1,2)) == 0)[0].tolist()

    if len(pos_slices) == 0 or len(neg_slices) == 0:
        continue

    random.shuffle(pos_slices)
    random.shuffle(neg_slices)
    pos_take = pos_slices[:POS_SLICES_PER_CASE]
    neg_take = neg_slices[:NEG_SLICES_PER_CASE]

    picks = [(z,1) for z in pos_take] + [(z,0) for z in neg_take]
    random.shuffle(picks)

    for z, lab in picks:
        img01 = safe_norm01(vol[z])
        Xt = to_tensor_rgb(img01, out_size=IMG_SIZE)
        X_list.append(Xt)
        y_list.append(lab)
        case_ids.append(ci)

    used_cases += 1

print(f"Cases used (mask found + both pos/neg slices): {used_cases}")
print(f"Total slices sampled: {len(X_list)}  (pos={sum(y_list)}, neg={len(y_list)-sum(y_list)})")

if len(X_list) < 20 or len(set(y_list)) < 2:
    raise RuntimeError(
        "Not enough slices or only one class found. "
        "Try MAX_CASES=None or increase POS/NEG_SLICES_PER_CASE."
    )

X = torch.stack(X_list, dim=0)  # [N,3,224,224]
y = np.array(y_list, dtype=int)
case_ids = np.array(case_ids, dtype=int)

# -------------------------
# Metrics helpers
# -------------------------
def youden_threshold(y_true, y_prob):
    fpr, tpr, thr = roc_curve(y_true, y_prob)
    j = tpr - fpr
    k = int(np.argmax(j))
    return float(thr[k])

def report(name, y_true, y_prob):
    auc = roc_auc_score(y_true, y_prob)
    thr = youden_threshold(y_true, y_prob)
    yhat = (y_prob >= thr).astype(int)

    acc = accuracy_score(y_true, yhat)
    f1  = f1_score(y_true, yhat, zero_division=0)
    tn, fp, fn, tp = confusion_matrix(y_true, yhat, labels=[0,1]).ravel()
    sens = tp / (tp + fn + 1e-9)
    spec = tn / (tn + fp + 1e-9)

    print(f"\n===== External Prostate158 TEST (slice-level) - {name} =====")
    print(f"N slices     : {len(y_true)}")
    print(f"AUC          : {auc:.4f}")
    print(f"Threshold    : {thr:.4f}")
    print(f"Accuracy     : {acc:.4f}")
    print(f"Sensitivity  : {sens:.4f}")
    print(f"Specificity  : {spec:.4f}")
    print(f"F1           : {f1:.4f}")
    print(f"TN FP FN TP  : {tn} {fp} {fn} {tp}")

# -------------------------
# Run inference
# -------------------------
@torch.no_grad()
def predict_probs(model, X):
    probs = []
    for i in range(0, len(X), BATCH):
        xb = X[i:i+BATCH].to(device)
        logits = model(xb)
        if isinstance(logits, (tuple, list)):
            logits = logits[0]
        logits = logits.view(-1)
        pb = torch.sigmoid(logits).detach().cpu().numpy()
        probs.append(pb)
    return np.concatenate(probs)

for mname, model in models.items():
    yprob = predict_probs(model, X)
    report(mname, y, yprob)

    # Case-level aggregation (informative only)
    case_probs = {}
    for cid, p in zip(case_ids, yprob):
        case_probs.setdefault(int(cid), []).append(float(p))
    # robust aggregation: mean of top-3 slice probs
    agg = {k: float(np.mean(sorted(v, reverse=True)[:3])) for k, v in case_probs.items()}
    vals = np.array([agg[k] for k in sorted(agg.keys())], dtype=float)
    print(f"Case-prob aggregate (top-3 mean) over {len(vals)} cases: min={vals.min():.4f}, median={np.median(vals):.4f}, max={vals.max():.4f}")

print("\nDONE.")
print("To strengthen: set MAX_CASES=None and/or POS/NEG_SLICES_PER_CASE=8 (slower but stronger).")

import numpy as np
import torch
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, f1_score, roc_curve

# ---------- ECE (calibration) ----------
def expected_calibration_error(y_true, y_prob, n_bins=10):
    y_true = np.asarray(y_true).astype(int)
    y_prob = np.asarray(y_prob).astype(float)
    bins = np.linspace(0.0, 1.0, n_bins + 1)
    ece = 0.0
    for i in range(n_bins):
        lo, hi = bins[i], bins[i+1]
        mask = (y_prob >= lo) & (y_prob < hi) if i < n_bins-1 else (y_prob >= lo) & (y_prob <= hi)
        if mask.sum() == 0:
            continue
        acc = y_true[mask].mean()
        conf = y_prob[mask].mean()
        ece += (mask.sum() / len(y_prob)) * abs(acc - conf)
    return float(ece)

def youden_threshold(y_true, y_prob):
    fpr, tpr, thr = roc_curve(y_true, y_prob)
    j = tpr - fpr
    k = int(np.argmax(j))
    return float(thr[k])

def report(name, y_true, y_prob):
    auc = roc_auc_score(y_true, y_prob)
    thr = youden_threshold(y_true, y_prob)
    yhat = (y_prob >= thr).astype(int)
    acc = accuracy_score(y_true, yhat)
    f1  = f1_score(y_true, yhat, zero_division=0)
    tn, fp, fn, tp = confusion_matrix(y_true, yhat, labels=[0,1]).ravel()
    sens = tp / (tp + fn + 1e-9)
    spec = tn / (tn + fp + 1e-9)
    ece  = expected_calibration_error(y_true, y_prob, n_bins=10)

    print(f"\n===== {name} =====")
    print(f"AUC          : {auc:.4f}")
    print(f"Threshold    : {thr:.4f}")
    print(f"Accuracy     : {acc:.4f}")
    print(f"Sensitivity  : {sens:.4f}")
    print(f"Specificity  : {spec:.4f}")
    print(f"F1           : {f1:.4f}")
    print(f"ECE (10 bins): {ece:.4f}")
    print(f"TN FP FN TP  : {tn} {fp} {fn} {tp}")
    return dict(AUC=auc, Thr=thr, Acc=acc, Sens=sens, Spec=spec, F1=f1, ECE=ece)

# ---------- TTA transforms ----------
def tta_batch(x):
    # x: [B,3,H,W]
    # fast TTA set: identity + hflip + vflip + small rotations via affine
    xs = [x,
          torch.flip(x, dims=[3]),  # hflip
          torch.flip(x, dims=[2])]  # vflip

    # small affine: +/-5 degrees
    B, C, H, W = x.shape
    angles = [5.0, -5.0]
    for a in angles:
        theta = torch.zeros((B,2,3), device=x.device, dtype=x.dtype)
        rad = a * np.pi / 180.0
        cos, sin = np.cos(rad), np.sin(rad)
        theta[:,0,0] = cos; theta[:,0,1] = -sin
        theta[:,1,0] = sin; theta[:,1,1] = cos
        grid = F.affine_grid(theta, size=x.size(), align_corners=False)
        xs.append(F.grid_sample(x, grid, align_corners=False, mode="bilinear", padding_mode="border"))
    return xs

@torch.no_grad()
def predict_probs(model, X, batch=16):
    model.eval()
    probs = []
    for i in range(0, len(X), batch):
        xb = X[i:i+batch].to(device)
        logits = model(xb)
        if isinstance(logits, (tuple, list)):
            logits = logits[0]
        logits = logits.view(-1)
        probs.append(torch.sigmoid(logits).detach().cpu().numpy())
    return np.concatenate(probs)

@torch.no_grad()
def predict_probs_tta(model, X, batch=16):
    model.eval()
    probs = []
    for i in range(0, len(X), batch):
        xb = X[i:i+batch].to(device)
        aug_list = tta_batch(xb)
        p_augs = []
        for xa in aug_list:
            logits = model(xa)
            if isinstance(logits, (tuple, list)):
                logits = logits[0]
            logits = logits.view(-1)
            p_augs.append(torch.sigmoid(logits))
        p_mean = torch.stack(p_augs, dim=0).mean(dim=0)
        probs.append(p_mean.detach().cpu().numpy())
    return np.concatenate(probs)

print("\n--- BASELINE vs TTA (External slice-level) ---")
for mname, model in models.items():
    yprob_base = predict_probs(model, X, batch=BATCH)
    yprob_tta  = predict_probs_tta(model, X, batch=BATCH)

    print(f"\nModel: {mname}")
    report(f"{mname} - BASELINE", y, yprob_base)
    report(f"{mname} - TTA",      y, yprob_tta)

print("\nDONE (TTA eval).")











# ============================================================
# COMPLETE PIPELINE (one cell)
# - Internal: ResNet50 frozen embeddings + LR(CV) + SVM(calibrated)
# - Saves: .joblib + .pkl
# - External: Prostate158 test download (robust) + slice-level eval
# - Pure classic: HOG + SVM(calibrated) (no pretrained / no deep learning)
# ============================================================

import os, sys, zipfile, glob, random, warnings, pickle, subprocess, re, time
from pathlib import Path
import numpy as np

warnings.filterwarnings("ignore")
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

def pip_install(pkgs):
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q"] + pkgs)

pip_install(["torchvision", "SimpleITK", "scikit-learn", "joblib", "scikit-image", "requests"])

# -------------------------
# Robust download helper (Zenodo-safe)
# -------------------------
import requests

def download_file(url: str, out_path: str, chunk=1024*1024, retries=5):
    out_path = str(out_path)
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    if os.path.exists(out_path) and os.path.getsize(out_path) > 5_000_000:
        print(f"Found existing: {out_path} ({os.path.getsize(out_path)/1e6:.1f} MB)")
        return

    # 1) try wget with redirects + retries
    wget_cmd = [
        "wget", "-L", "--tries=5", "--waitretry=1", "--timeout=30",
        "--retry-connrefused",
        "-O", out_path, url
    ]
    try:
        print(f"Trying wget -> {out_path}")
        subprocess.check_call(wget_cmd)
        if os.path.getsize(out_path) > 5_000_000:
            return
    except Exception as e:
        print("wget failed:", str(e)[:200])

    # 2) try curl
    curl_cmd = ["curl", "-L", "-o", out_path, url]
    try:
        print("Trying curl...")
        subprocess.check_call(curl_cmd)
        if os.path.getsize(out_path) > 5_000_000:
            return
    except Exception as e:
        print("curl failed:", str(e)[:200])

    # 3) python streaming with retries
    print("Trying Python requests streaming...")
    last_err = None
    for k in range(retries):
        try:
            with requests.get(url, stream=True, allow_redirects=True, timeout=60) as r:
                r.raise_for_status()
                total = int(r.headers.get("content-length", 0))
                tmp = out_path + ".part"
                written = 0
                t0 = time.time()
                with open(tmp, "wb") as f:
                    for chunk_bytes in r.iter_content(chunk_size=chunk):
                        if not chunk_bytes:
                            continue
                        f.write(chunk_bytes)
                        written += len(chunk_bytes)
                        if total > 0 and (time.time() - t0) > 1.0:
                            pct = 100.0 * written / total
                            print(f"\r  {pct:5.1f}% ({written/1e6:.1f}/{total/1e6:.1f} MB)", end="")
                            t0 = time.time()
                print()
                os.replace(tmp, out_path)
                if os.path.getsize(out_path) > 5_000_000:
                    return
        except Exception as e:
            last_err = e
            print(f"  attempt {k+1}/{retries} failed: {str(e)[:200]}")
            time.sleep(2)

    raise RuntimeError(f"All download methods failed for: {url}\nLast error: {last_err}")

# -------------------------
# A) INTERNAL DATA (your zips)
# -------------------------
CANCER_ZIP = "/content/Cancer.zip"
NORMAL_ZIP = "/content/Normal.zip"
DATA_DIR   = "/content/ml_baseline_data"
CANCER_DIR = os.path.join(DATA_DIR, "Cancer")
NORMAL_DIR = os.path.join(DATA_DIR, "Normal")
os.makedirs(CANCER_DIR, exist_ok=True)
os.makedirs(NORMAL_DIR, exist_ok=True)

def unzip_if_needed(zip_path, out_dir):
    if not os.path.exists(zip_path):
        raise FileNotFoundError(f"Missing: {zip_path}")
    existing = glob.glob(os.path.join(out_dir, "**", "*.*"), recursive=True)
    if len(existing) > 0:
        return
    print(f"Unzipping {zip_path} -> {out_dir}")
    with zipfile.ZipFile(zip_path, "r") as zf:
        zf.extractall(out_dir)

unzip_if_needed(CANCER_ZIP, CANCER_DIR)
unzip_if_needed(NORMAL_ZIP, NORMAL_DIR)

IMG_EXTS = (".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff")
def collect_images(folder):
    paths = []
    for root, _, files in os.walk(folder):
        for f in files:
            if f.lower().endswith(IMG_EXTS):
                paths.append(os.path.join(root, f))
    return sorted(paths)

cancer_paths = collect_images(CANCER_DIR)
normal_paths = collect_images(NORMAL_DIR)
print("Cancer images:", len(cancer_paths))
print("Normal images:", len(normal_paths))
if len(cancer_paths) < 10 or len(normal_paths) < 10:
    raise RuntimeError("Too few images. Check your zip contents.")

X_paths = cancer_paths + normal_paths
y = np.array([1]*len(cancer_paths) + [0]*len(normal_paths), dtype=int)

# -------------------------
# Torch frozen ResNet50 embeddings
# -------------------------
import torch
import torch.nn as nn
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import torchvision.models as tvm
from torchvision.models import ResNet50_Weights

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

weights = ResNet50_Weights.DEFAULT
preprocess = weights.transforms()

class ImgDataset(Dataset):
    def __init__(self, paths, labels):
        self.paths = paths
        self.labels = labels
    def __len__(self):
        return len(self.paths)
    def __getitem__(self, idx):
        p = self.paths[idx]
        img = Image.open(p).convert("L").convert("RGB")
        x = preprocess(img)
        return x, int(self.labels[idx])

resnet_feat = tvm.resnet50(weights=weights)
resnet_feat.fc = nn.Identity()  # 2048-d
resnet_feat = resnet_feat.to(device).eval()
for p in resnet_feat.parameters():
    p.requires_grad = False

@torch.no_grad()
def extract_features(paths, labels, batch=32):
    ds = ImgDataset(paths, labels)
    dl = DataLoader(ds, batch_size=batch, shuffle=False, num_workers=2, pin_memory=True)
    feats, labs = [], []
    for xb, yb in dl:
        xb = xb.to(device)
        fb = resnet_feat(xb)
        feats.append(fb.detach().cpu().numpy())
        labs.append(np.array(yb, dtype=int))
    return np.vstack(feats), np.concatenate(labs)

# -------------------------
# Split
# -------------------------
from sklearn.model_selection import train_test_split

idx_all = np.arange(len(X_paths))
idx_train, idx_test = train_test_split(idx_all, test_size=0.20, random_state=SEED, stratify=y)
idx_train, idx_val  = train_test_split(idx_train, test_size=0.20, random_state=SEED, stratify=y[idx_train])

def subset(paths, labels, idx):
    return [paths[i] for i in idx], labels[idx]

Xtr_p, ytr = subset(X_paths, y, idx_train)
Xva_p, yva = subset(X_paths, y, idx_val)
Xte_p, yte = subset(X_paths, y, idx_test)
print(f"Split: train={len(Xtr_p)} val={len(Xva_p)} test={len(Xte_p)}")

Ftr, ytr2 = extract_features(Xtr_p, ytr, batch=32)
Fva, yva2 = extract_features(Xva_p, yva, batch=32)
Fte, yte2 = extract_features(Xte_p, yte, batch=32)

# -------------------------
# ML models: LR(CV) + SVM(calibrated)
# -------------------------
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegressionCV
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, roc_curve
import joblib

def eval_metrics(name, y_true, y_prob, thr=0.5):
    yhat = (y_prob >= thr).astype(int)
    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) == 2 else float("nan")
    acc = accuracy_score(y_true, yhat)
    f1  = f1_score(y_true, yhat, zero_division=0)
    tn, fp, fn, tp = confusion_matrix(y_true, yhat, labels=[0,1]).ravel()
    sens = tp / (tp + fn + 1e-9)
    spec = tn / (tn + fp + 1e-9)
    print(f"\n=== {name} (thr={thr:.4f}) ===")
    print(f"AUC         : {auc:.4f}" if auc==auc else "AUC         : nan")
    print(f"Accuracy    : {acc:.4f}")
    print(f"F1          : {f1:.4f}")
    print(f"Sensitivity : {sens:.4f}")
    print(f"Specificity : {spec:.4f}")
    print(f"TN FP FN TP : {tn} {fp} {fn} {tp}")
    return dict(AUC=auc, Acc=acc, F1=f1, Sens=sens, Spec=spec, TN=tn, FP=fp, FN=fn, TP=tp)

def threshold_fn_priority(y_true, y_prob, min_sens=0.95):
    thr_grid = np.unique(np.clip(y_prob, 0, 1))
    best_thr = 0.0
    best_fp = 10**18
    for thr in thr_grid:
        yhat = (y_prob >= thr).astype(int)
        tn, fp, fn, tp = confusion_matrix(y_true, yhat, labels=[0,1]).ravel()
        sens = tp / (tp + fn + 1e-9)
        if sens >= min_sens:
            if fp < best_fp:
                best_fp = fp
                best_thr = float(thr)
    return best_thr

lr = Pipeline([
    ("scaler", StandardScaler()),
    ("lr", LogisticRegressionCV(
        Cs=np.logspace(-4, 4, 15),
        cv=5,
        class_weight="balanced",
        max_iter=5000,
        solver="lbfgs",
        scoring="roc_auc"
    ))
])
lr.fit(Ftr, ytr2)

svm_base = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", LinearSVC(C=1.0, class_weight="balanced"))
])
svm_cal = CalibratedClassifierCV(svm_base, method="sigmoid", cv=5)
svm_cal.fit(Ftr, ytr2)

print("\n--- INTERNAL (fixed thr=0.5) ---")
p_lr_val  = lr.predict_proba(Fva)[:,1];  eval_metrics("LR-CV VAL",  yva2, p_lr_val,  0.5)
p_lr_test = lr.predict_proba(Fte)[:,1];  eval_metrics("LR-CV TEST", yte2, p_lr_test, 0.5)
p_svm_val  = svm_cal.predict_proba(Fva)[:,1]; eval_metrics("SVM-Cal VAL",  yva2, p_svm_val,  0.5)
p_svm_test = svm_cal.predict_proba(Fte)[:,1]; eval_metrics("SVM-Cal TEST", yte2, p_svm_test, 0.5)

thr_lr  = threshold_fn_priority(yva2, p_lr_val,  min_sens=0.95)
thr_svm = threshold_fn_priority(yva2, p_svm_val, min_sens=0.95)
print(f"\nVAL-derived FN-priority thresholds (min sens 0.95): LR={thr_lr:.4f}, SVM={thr_svm:.4f}")
eval_metrics("LR-CV TEST (FN-priority thr from VAL)",   yte2, p_lr_test,  thr_lr)
eval_metrics("SVM-Cal TEST (FN-priority thr from VAL)", yte2, p_svm_test, thr_svm)

# -------------------------
# Save models (joblib + pkl)
# -------------------------
LR_JOBLIB  = "/content/resnet50feat_logregCV.joblib"
SVM_JOBLIB = "/content/resnet50feat_svmCal.joblib"
joblib.dump(lr, LR_JOBLIB)
joblib.dump(svm_cal, SVM_JOBLIB)

LR_PKL  = "/content/resnet50feat_logregCV.pkl"
SVM_PKL = "/content/resnet50feat_svmCal.pkl"
with open(LR_PKL, "wb") as f: pickle.dump(lr, f)
with open(SVM_PKL, "wb") as f: pickle.dump(svm_cal, f)

print("\nSaved:")
print(" ", LR_JOBLIB)
print(" ", SVM_JOBLIB)
print(" ", LR_PKL)
print(" ", SVM_PKL)

# ============================================================
# B) EXTERNAL: Prostate158 test download + slice-level eval
# ============================================================
import SimpleITK as sitk

P158_ROOT = Path("/content/prostate158_test")
P158_ZIP  = P158_ROOT / "prostate158_test.zip"
P158_EXT  = P158_ROOT / "extracted"
P158_URL  = "https://zenodo.org/records/6592345/files/prostate158_test.zip?download=1"

P158_ROOT.mkdir(parents=True, exist_ok=True)
download_file(P158_URL, str(P158_ZIP))

if not P158_EXT.exists():
    print("Unzipping Prostate158...")
    P158_EXT.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(P158_ZIP, "r") as zf:
        zf.extractall(P158_EXT)
else:
    print("Prostate158 already extracted:", P158_EXT)

# slice sampling controls
MAX_CASES_EXT = 19
POS_SLICES_PER_CASE_EXT = 4
NEG_SLICES_PER_CASE_EXT = 4
MASK_UNIQUE_MAX = 32
LESION_FRAC_MAX = 0.03
MASK_FRAC_MAX   = 0.80

def is_volume(p: Path) -> bool:
    n = p.name.lower()
    return p.is_file() and (n.endswith(".mha") or n.endswith(".nii") or n.endswith(".nii.gz"))

def read_vol(path: Path) -> np.ndarray:
    img = sitk.ReadImage(str(path))
    return sitk.GetArrayFromImage(img).astype(np.float32)  # (z,y,x)

def norm_name(s: str) -> str:
    return re.sub(r"[^a-z0-9]+", "_", s.lower())

def looks_like_t2(p: Path) -> bool:
    n = norm_name(p.name)
    if ("t2" not in n) and ("t2w" not in n):
        return False
    if any(k in n for k in ["adc","dwi","bval","bvalue","ktrans"]):
        return False
    if any(k in n for k in ["mask","seg","label","anno","annot"]):
        return False
    return True

def mask_likeness(arr: np.ndarray):
    flat = arr.ravel()
    if flat.size > 200_000:
        idx = np.random.choice(flat.size, 200_000, replace=False)
        samp = flat[idx]
    else:
        samp = flat
    uq = int(np.unique(samp).size)
    if uq > MASK_UNIQUE_MAX:
        return None
    frac = float(np.count_nonzero(arr)) / float(arr.size)
    if frac <= 0.0 or frac >= MASK_FRAC_MAX:
        return None
    return (frac, uq)

def pick_lesion_mask(folder: Path, t2_path: Path):
    vols = [p for p in folder.iterdir() if is_volume(p)]
    others = [p for p in vols if p.resolve() != t2_path.resolve()]
    scored = []
    for p in others:
        try:
            a = read_vol(p)
            sc = mask_likeness(a)
            if sc is None:
                continue
            frac, uq = sc
            scored.append((frac, uq, p))
        except Exception:
            continue
    if not scored:
        return None
    lesion_like = [x for x in scored if x[0] < LESION_FRAC_MAX]
    if lesion_like:
        lesion_like.sort(key=lambda x: x[0])
        return lesion_like[0][2]
    return None

all_vols = [p for p in P158_EXT.rglob("*") if is_volume(p)]
t2_files = [p for p in all_vols if looks_like_t2(p)]
case_folders = sorted({p.parent for p in t2_files})
case_folders = case_folders[:MAX_CASES_EXT] if MAX_CASES_EXT is not None else case_folders
print(f"\nExternal Prostate158 case folders considered: {len(case_folders)}")

Xext_imgs, yext = [], []
used = 0

for folder in case_folders:
    vols = [p for p in folder.iterdir() if is_volume(p)]
    t2_candidates = [p for p in vols if looks_like_t2(p)]
    if not t2_candidates:
        continue
    t2_path = sorted(t2_candidates, key=lambda x: len(x.name))[0]
    mask_path = pick_lesion_mask(folder, t2_path)
    if mask_path is None:
        continue

    try:
        vol = read_vol(t2_path)
        msk = read_vol(mask_path)
    except Exception:
        continue
    if vol.ndim != 3 or msk.ndim != 3 or vol.shape != msk.shape:
        continue

    pos_slices = np.where(np.sum(msk > 0, axis=(1,2)) > 0)[0].tolist()
    neg_slices = np.where(np.sum(msk > 0, axis=(1,2)) == 0)[0].tolist()
    if len(pos_slices) == 0 or len(neg_slices) == 0:
        continue

    random.shuffle(pos_slices); random.shuffle(neg_slices)
    pos_take = pos_slices[:POS_SLICES_PER_CASE_EXT]
    neg_take = neg_slices[:NEG_SLICES_PER_CASE_EXT]

    def slice_to_01(img2d):
        p1, p99 = np.percentile(img2d, 1), np.percentile(img2d, 99)
        x = (img2d - p1) / (p99 - p1 + 1e-6)
        return np.clip(x, 0, 1)

    for z in pos_take:
        Xext_imgs.append(slice_to_01(vol[z])); yext.append(1)
    for z in neg_take:
        Xext_imgs.append(slice_to_01(vol[z])); yext.append(0)
    used += 1

print(f"External cases used (mask+pos/neg slices): {used}")
print(f"External slices sampled: {len(Xext_imgs)} (pos={sum(yext)}, neg={len(yext)-sum(yext)})")
if len(Xext_imgs) < 30 or len(set(yext)) < 2:
    raise RuntimeError("Not enough external slices/classes. Try MAX_CASES_EXT=None or increase slice counts.")

# Convert external slices -> ResNet50 embeddings
from PIL import Image

def slice01_to_tensor(img01):
    im = Image.fromarray((img01*255).astype(np.uint8)).convert("L").convert("RGB")
    return preprocess(im)

Xext_t = torch.stack([slice01_to_tensor(x) for x in Xext_imgs], dim=0)
yext = np.array(yext, dtype=int)

@torch.no_grad()
def extract_features_from_tensor(batch_tensor, batch=32):
    feats = []
    for i in range(0, len(batch_tensor), batch):
        xb = batch_tensor[i:i+batch].to(device)
        fb = resnet_feat(xb)
        feats.append(fb.detach().cpu().numpy())
    return np.vstack(feats)

Fext = extract_features_from_tensor(Xext_t, batch=32)

print("\n--- EXTERNAL RESULTS (Prostate158 slice-level) ---")
p_lr_ext  = lr.predict_proba(Fext)[:,1]
p_svm_ext = svm_cal.predict_proba(Fext)[:,1]
eval_metrics("LR-CV EXTERNAL (thr=0.5)",          yext, p_lr_ext,  0.5)
eval_metrics("SVM-Cal EXTERNAL (thr=0.5)",        yext, p_svm_ext, 0.5)
eval_metrics(f"LR-CV EXTERNAL (FN-priority thr={thr_lr:.4f} from VAL)",   yext, p_lr_ext,  thr_lr)
eval_metrics(f"SVM-Cal EXTERNAL (FN-priority thr={thr_svm:.4f} from VAL)", yext, p_svm_ext, thr_svm)

# ============================================================
# C) PURE CLASSIC (no pretrained): HOG + calibrated Linear SVM
# ============================================================
from skimage.feature import hog
from skimage.color import rgb2gray
from skimage.transform import resize
from sklearn.calibration import CalibratedClassifierCV

HOG_SIZE = 128

def load_img_gray(path):
    img = Image.open(path).convert("RGB")
    img = np.asarray(img).astype(np.float32) / 255.0
    g = rgb2gray(img)
    g = resize(g, (HOG_SIZE, HOG_SIZE), anti_aliasing=True)
    return g

def hog_features(img_gray):
    return hog(img_gray, orientations=9, pixels_per_cell=(8,8), cells_per_block=(2,2),
               block_norm="L2-Hys", feature_vector=True)

def build_hog_matrix(paths):
    feats = []
    for p in paths:
        g = load_img_gray(p)
        feats.append(hog_features(g))
    return np.vstack(feats)

print("\nBuilding HOG features (pure classic)...")
Htr = build_hog_matrix(Xtr_p)
Hva = build_hog_matrix(Xva_p)
Hte = build_hog_matrix(Xte_p)

from sklearn.svm import LinearSVC
hog_svm_base = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", LinearSVC(C=1.0, class_weight="balanced"))
])
hog_svm = CalibratedClassifierCV(hog_svm_base, method="sigmoid", cv=5)
hog_svm.fit(Htr, ytr2)

p_hog_val  = hog_svm.predict_proba(Hva)[:,1]
p_hog_test = hog_svm.predict_proba(Hte)[:,1]
eval_metrics("HOG+SVM VAL (thr=0.5)",  yva2, p_hog_val,  0.5)
eval_metrics("HOG+SVM TEST (thr=0.5)", yte2, p_hog_test, 0.5)

HOG_JOBLIB = "/content/hog_svmCal.joblib"
HOG_PKL    = "/content/hog_svmCal.pkl"
joblib.dump(hog_svm, HOG_JOBLIB)
with open(HOG_PKL, "wb") as f: pickle.dump(hog_svm, f)
print("\nSaved pure-classic models:", HOG_JOBLIB, "and", HOG_PKL)

print("\nDONE.")

!find /content -mindepth 1 -maxdepth 1 -exec rm -rf {} +

!zip -r /content/all_results.zip /content -x "/content/all_results.zip" "/content/sample_data/*" && ls -lh /content/all_results.zip



# ============================================================
# ONE CELL: Classic-only + Pretrained+Classic + External test
# Saves: .pkl + .pt for all sklearn models + zip all /content
# ============================================================

import os, sys, zipfile, glob, random, warnings, pickle, subprocess, re, time
from pathlib import Path
import numpy as np
warnings.filterwarnings("ignore")

SEED = 42
random.seed(SEED)
np.random.seed(SEED)

def pip_install(pkgs):
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q"] + pkgs)

pip_install(["torch", "torchvision", "SimpleITK", "scikit-learn", "joblib", "scikit-image", "requests"])

import torch
import torchvision.models as tvm
import torch.nn as nn
from PIL import Image
import requests
import SimpleITK as sitk

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.calibration import CalibratedClassifierCV
from sklearn.linear_model import LogisticRegressionCV
from sklearn.svm import SVC, LinearSVC
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix

from skimage.feature import hog
from skimage.color import rgb2gray
from skimage.transform import resize

# --------------------------
# Device
# --------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# --------------------------
# Robust downloader (Zenodo-safe)
# --------------------------
def download_file(url: str, out_path: str, chunk=1024*1024, retries=5):
    out_path = str(out_path)
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    if os.path.exists(out_path) and os.path.getsize(out_path) > 5_000_000:
        print(f"Found existing: {out_path} ({os.path.getsize(out_path)/1e6:.1f} MB)")
        return

    # 1) wget with redirects/retries
    try:
        print(f"Trying wget -> {out_path}")
        subprocess.check_call([
            "wget", "-L", "--tries=5", "--waitretry=1", "--timeout=30", "--retry-connrefused",
            "-O", out_path, url
        ])
        if os.path.getsize(out_path) > 5_000_000:
            return
    except Exception as e:
        print("wget failed:", str(e)[:160])

    # 2) curl
    try:
        print("Trying curl...")
        subprocess.check_call(["curl", "-L", "-o", out_path, url])
        if os.path.getsize(out_path) > 5_000_000:
            return
    except Exception as e:
        print("curl failed:", str(e)[:160])

    # 3) python streaming
    print("Trying Python requests streaming...")
    last_err = None
    for k in range(retries):
        try:
            with requests.get(url, stream=True, allow_redirects=True, timeout=60) as r:
                r.raise_for_status()
                total = int(r.headers.get("content-length", 0))
                tmp = out_path + ".part"
                written = 0
                t0 = time.time()
                with open(tmp, "wb") as f:
                    for cb in r.iter_content(chunk_size=chunk):
                        if not cb:
                            continue
                        f.write(cb)
                        written += len(cb)
                        if total > 0 and (time.time() - t0) > 1.0:
                            pct = 100.0 * written / total
                            print(f"\r  {pct:5.1f}% ({written/1e6:.1f}/{total/1e6:.1f} MB)", end="")
                            t0 = time.time()
                print()
                os.replace(tmp, out_path)
                if os.path.getsize(out_path) > 5_000_000:
                    return
        except Exception as e:
            last_err = e
            print(f"  attempt {k+1}/{retries} failed: {str(e)[:160]}")
            time.sleep(2)

    raise RuntimeError(f"All download methods failed for: {url}\nLast error: {last_err}")

# --------------------------
# Metrics helper
# --------------------------
def eval_metrics(title, y_true, y_prob, thr=0.5):
    y_true = np.asarray(y_true).astype(int)
    y_prob = np.asarray(y_prob).astype(float)
    y_hat = (y_prob >= thr).astype(int)

    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) == 2 else float("nan")
    acc = accuracy_score(y_true, y_hat)
    f1  = f1_score(y_true, y_hat, zero_division=0)
    tn, fp, fn, tp = confusion_matrix(y_true, y_hat, labels=[0,1]).ravel()
    sens = tp / (tp + fn + 1e-9)
    spec = tn / (tn + fp + 1e-9)

    print(f"\n===== {title} (thr={thr:.4f}) =====")
    print(f"AUC         : {auc:.4f}" if auc==auc else "AUC         : nan")
    print(f"Accuracy    : {acc:.4f}")
    print(f"F1          : {f1:.4f}")
    print(f"Sensitivity : {sens:.4f}")
    print(f"Specificity : {spec:.4f}")
    print(f"TN FP FN TP : {tn} {fp} {fn} {tp}")
    return dict(Title=title, AUC=auc, Accuracy=acc, F1=f1, Sensitivity=sens, Specificity=spec, TN=tn, FP=fp, FN=fn, TP=tp, Threshold=thr)

# FN-first threshold selection: keep sensitivity >= target, then minimize FP
def threshold_fn_priority(y_true, y_prob, min_sens=0.95):
    y_true = np.asarray(y_true).astype(int)
    y_prob = np.asarray(y_prob).astype(float)
    thr_grid = np.unique(np.clip(y_prob, 0, 1))
    best_thr, best_fp = 0.0, 10**18
    for thr in thr_grid:
        y_hat = (y_prob >= thr).astype(int)
        tn, fp, fn, tp = confusion_matrix(y_true, y_hat, labels=[0,1]).ravel()
        sens = tp / (tp + fn + 1e-9)
        if sens >= min_sens and fp < best_fp:
            best_fp = fp
            best_thr = float(thr)
    return best_thr

# --------------------------
# 0) Load INTERNAL dataset (your zips)
# --------------------------
CANCER_ZIP = "/content/Cancer.zip"
NORMAL_ZIP = "/content/Normal.zip"
DATA_DIR   = "/content/data_internal"
CANCER_DIR = os.path.join(DATA_DIR, "Cancer")
NORMAL_DIR = os.path.join(DATA_DIR, "Normal")
os.makedirs(CANCER_DIR, exist_ok=True)
os.makedirs(NORMAL_DIR, exist_ok=True)

def unzip_if_needed(zip_path, out_dir):
    if not os.path.exists(zip_path):
        raise FileNotFoundError(f"Missing: {zip_path}")
    if len(glob.glob(os.path.join(out_dir, "**", "*.*"), recursive=True)) > 0:
        return
    print(f"Unzipping {zip_path} -> {out_dir}")
    with zipfile.ZipFile(zip_path, "r") as zf:
        zf.extractall(out_dir)

unzip_if_needed(CANCER_ZIP, CANCER_DIR)
unzip_if_needed(NORMAL_ZIP, NORMAL_DIR)

IMG_EXTS = (".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff")
def collect_images(folder):
    paths = []
    for root, _, files in os.walk(folder):
        for f in files:
            if f.lower().endswith(IMG_EXTS):
                paths.append(os.path.join(root, f))
    return sorted(paths)

cancer_paths = collect_images(CANCER_DIR)
normal_paths = collect_images(NORMAL_DIR)
print("Internal Cancer:", len(cancer_paths), "Internal Normal:", len(normal_paths))
if len(cancer_paths) < 10 or len(normal_paths) < 10:
    raise RuntimeError("Too few internal images. Check your zip content.")

X_paths = cancer_paths + normal_paths
y_all = np.array([1]*len(cancer_paths) + [0]*len(normal_paths), dtype=int)

# split
idx = np.arange(len(X_paths))
idx_tr, idx_te = train_test_split(idx, test_size=0.20, random_state=SEED, stratify=y_all)
idx_tr, idx_va = train_test_split(idx_tr, test_size=0.20, random_state=SEED, stratify=y_all[idx_tr])

def subset(paths, y, idxs):
    return [paths[i] for i in idxs], y[idxs]

Xtr, ytr = subset(X_paths, y_all, idx_tr)
Xva, yva = subset(X_paths, y_all, idx_va)
Xte, yte = subset(X_paths, y_all, idx_te)
print(f"Split: train={len(Xtr)} val={len(Xva)} test={len(Xte)}")

# ============================================================
# 1) STRONG PURE CLASSIC (NO DL, NO PRETRAINED):
#    HOG -> SVM(RBF) with CV tuning + calibration
# ============================================================
HOG_SIZE = 128
def load_img_gray(path):
    img = Image.open(path).convert("RGB")
    arr = np.asarray(img).astype(np.float32) / 255.0
    g = rgb2gray(arr)
    g = resize(g, (HOG_SIZE, HOG_SIZE), anti_aliasing=True)
    return g

def hog_feat(g):
    return hog(
        g, orientations=9, pixels_per_cell=(8,8), cells_per_block=(2,2),
        block_norm="L2-Hys", feature_vector=True
    )

def build_hog_matrix(paths):
    feats = []
    for p in paths:
        g = load_img_gray(p)
        feats.append(hog_feat(g))
    return np.vstack(feats)

print("\n[Classic-only] Building HOG features...")
Htr = build_hog_matrix(Xtr)
Hva = build_hog_matrix(Xva)
Hte = build_hog_matrix(Xte)

# Tune SVM RBF on TRAIN via CV (reduces overfit vs fixed params)
svm_rbf = Pipeline([
    ("scaler", StandardScaler()),
    ("svc", SVC(kernel="rbf", class_weight="balanced"))
])

param_grid = {
    "svc__C": [0.1, 1, 10, 30],
    "svc__gamma": ["scale", 0.01, 0.03, 0.1]
}
gs = GridSearchCV(svm_rbf, param_grid=param_grid, cv=5, scoring="roc_auc", n_jobs=-1)
gs.fit(Htr, ytr)
best_svm = gs.best_estimator_
print("[Classic-only] Best HOG+SVM params:", gs.best_params_)

# Calibrate probabilities (better thresholding / reporting)
hog_svm = CalibratedClassifierCV(best_svm, method="sigmoid", cv=5)
hog_svm.fit(Htr, ytr)

p_hog_val  = hog_svm.predict_proba(Hva)[:,1]
p_hog_test = hog_svm.predict_proba(Hte)[:,1]
thr_hog = threshold_fn_priority(yva, p_hog_val, min_sens=0.95)

m1 = eval_metrics("PURE_CLASSIC HOG+SVM VAL",  yva, p_hog_val,  0.5)
m2 = eval_metrics("PURE_CLASSIC HOG+SVM TEST", yte, p_hog_test, 0.5)
m3 = eval_metrics(f"PURE_CLASSIC HOG+SVM TEST (FN-priority thr={thr_hog:.4f})", yte, p_hog_test, thr_hog)

# Save classic-only model (.pkl + .pt)
HOG_PKL = "/content/pureclassic_hog_svm.pkl"
with open(HOG_PKL, "wb") as f:
    pickle.dump(hog_svm, f)

HOG_PT = "/content/pureclassic_hog_svm.pt"
torch.save({"type":"sklearn_pipeline", "payload": pickle.dumps(hog_svm)}, HOG_PT)
print("Saved:", HOG_PKL, "and", HOG_PT)

# ============================================================
# 2) PRETRAINED + CLASSIC ML:
#    Frozen ResNet50 embeddings -> LR + calibrated linear SVM
# ============================================================
from torchvision.models import ResNet50_Weights
weights50 = ResNet50_Weights.DEFAULT
preprocess50 = weights50.transforms()

class ResNet50DS(torch.utils.data.Dataset):
    def __init__(self, paths, labels):
        self.paths = paths; self.labels = labels
    def __len__(self): return len(self.paths)
    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert("L").convert("RGB")
        return preprocess50(img), int(self.labels[idx])

resnet50_feat = tvm.resnet50(weights=weights50)
resnet50_feat.fc = nn.Identity()   # 2048-d embedding
resnet50_feat = resnet50_feat.to(device).eval()
for p in resnet50_feat.parameters():
    p.requires_grad = False

@torch.no_grad()
def extract_resnet50_feats(paths, labels, batch=32):
    ds = ResNet50DS(paths, labels)
    dl = torch.utils.data.DataLoader(ds, batch_size=batch, shuffle=False, num_workers=2, pin_memory=True)
    feats, ys = [], []
    for xb, yb in dl:
        xb = xb.to(device)
        fb = resnet50_feat(xb).detach().cpu().numpy()
        feats.append(fb); ys.append(np.array(yb, dtype=int))
    return np.vstack(feats), np.concatenate(ys)

print("\n[Pretrained+Classic] Extracting ResNet50 embeddings...")
Ftr, _ = extract_resnet50_feats(Xtr, ytr, batch=32)
Fva, _ = extract_resnet50_feats(Xva, yva, batch=32)
Fte, _ = extract_resnet50_feats(Xte, yte, batch=32)

# Logistic Regression CV
lr = Pipeline([
    ("scaler", StandardScaler()),
    ("lr", LogisticRegressionCV(
        Cs=np.logspace(-4, 4, 15),
        cv=5,
        class_weight="balanced",
        max_iter=5000,
        solver="lbfgs",
        scoring="roc_auc"
    ))
])
lr.fit(Ftr, ytr)

# Linear SVM + calibration
svm_lin = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", LinearSVC(C=1.0, class_weight="balanced"))
])
svm_cal = CalibratedClassifierCV(svm_lin, method="sigmoid", cv=5)
svm_cal.fit(Ftr, ytr)

p_lr_val  = lr.predict_proba(Fva)[:,1]
p_lr_test = lr.predict_proba(Fte)[:,1]
p_svm_val  = svm_cal.predict_proba(Fva)[:,1]
p_svm_test = svm_cal.predict_proba(Fte)[:,1]

thr_lr  = threshold_fn_priority(yva, p_lr_val,  min_sens=0.95)
thr_svm = threshold_fn_priority(yva, p_svm_val, min_sens=0.95)

eval_metrics("PRETRAINED+CLASSIC LR VAL",  yva, p_lr_val,  0.5)
eval_metrics("PRETRAINED+CLASSIC LR TEST", yte, p_lr_test, 0.5)
eval_metrics("PRETRAINED+CLASSIC SVM VAL",  yva, p_svm_val,  0.5)
eval_metrics("PRETRAINED+CLASSIC SVM TEST", yte, p_svm_test, 0.5)

eval_metrics(f"PRETRAINED+CLASSIC LR TEST (FN-priority thr={thr_lr:.4f})",   yte, p_lr_test,  thr_lr)
eval_metrics(f"PRETRAINED+CLASSIC SVM TEST (FN-priority thr={thr_svm:.4f})", yte, p_svm_test, thr_svm)

# Save pretrained+classic models (.pkl + .pt)
LR_PKL = "/content/pretrained_resnet50_LR.pkl"
SVM_PKL = "/content/pretrained_resnet50_SVM.pkl"
with open(LR_PKL, "wb") as f: pickle.dump(lr, f)
with open(SVM_PKL, "wb") as f: pickle.dump(svm_cal, f)

LR_PT = "/content/pretrained_resnet50_LR.pt"
SVM_PT = "/content/pretrained_resnet50_SVM.pt"
torch.save({"type":"sklearn_pipeline", "payload": pickle.dumps(lr)}, LR_PT)
torch.save({"type":"sklearn_pipeline", "payload": pickle.dumps(svm_cal)}, SVM_PT)
print("Saved:", LR_PKL, LR_PT, SVM_PKL, SVM_PT)

# ============================================================
# 3) EXTERNAL TEST (FAST): Prostate158 test (~203MB)
#    Sample few cases/slices and evaluate:
#    - HOG+SVM (pure classic)
#    - ResNet50+LR / ResNet50+SVM (pretrained+classic)
# ============================================================
P158_URL  = "https://zenodo.org/records/6592345/files/prostate158_test.zip?download=1"
P158_ROOT = Path("/content/prostate158_test")
P158_ZIP  = P158_ROOT / "prostate158_test.zip"
P158_EXT  = P158_ROOT / "extracted"
P158_ROOT.mkdir(parents=True, exist_ok=True)

download_file(P158_URL, str(P158_ZIP))
if not P158_EXT.exists():
    print("Unzipping Prostate158...")
    P158_EXT.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(P158_ZIP, "r") as zf:
        zf.extractall(P158_EXT)
else:
    print("Prostate158 already extracted.")

# Fast limits (~1015 minutes typical on Colab GPU)
MAX_CASES_EXT = 15
POS_SLICES_PER_CASE = 4
NEG_SLICES_PER_CASE = 4

# Heuristics to find T2 & lesion-mask-like volumes
MASK_UNIQUE_MAX = 32
LESION_FRAC_MAX = 0.03
MASK_FRAC_MAX   = 0.80

def is_volume(p: Path) -> bool:
    n = p.name.lower()
    return p.is_file() and (n.endswith(".mha") or n.endswith(".nii") or n.endswith(".nii.gz"))

def read_vol(path: Path) -> np.ndarray:
    img = sitk.ReadImage(str(path))
    return sitk.GetArrayFromImage(img).astype(np.float32)  # (z,y,x)

def norm_name(s: str) -> str:
    return re.sub(r"[^a-z0-9]+", "_", s.lower())

def looks_like_t2(p: Path) -> bool:
    n = norm_name(p.name)
    if ("t2" not in n) and ("t2w" not in n): return False
    if any(k in n for k in ["adc","dwi","bval","bvalue","ktrans"]): return False
    if any(k in n for k in ["mask","seg","label","anno","annot"]): return False
    return True

def mask_likeness(arr: np.ndarray):
    flat = arr.ravel()
    samp = flat[np.random.choice(flat.size, min(flat.size, 200_000), replace=False)]
    uq = int(np.unique(samp).size)
    if uq > MASK_UNIQUE_MAX: return None
    frac = float(np.count_nonzero(arr)) / float(arr.size)
    if frac <= 0.0 or frac >= MASK_FRAC_MAX: return None
    return frac, uq

def pick_lesion_mask(folder: Path, t2_path: Path):
    vols = [p for p in folder.iterdir() if is_volume(p)]
    others = [p for p in vols if p.resolve() != t2_path.resolve()]
    scored = []
    for p in others:
        try:
            a = read_vol(p)
            sc = mask_likeness(a)
            if sc is None:
                continue
            frac, uq = sc
            scored.append((frac, uq, p))
        except Exception:
            continue
    if not scored:
        return None
    lesion_like = [x for x in scored if x[0] < LESION_FRAC_MAX]
    if lesion_like:
        lesion_like.sort(key=lambda x: x[0])
        return lesion_like[0][2]
    return None

def slice_to_01(img2d):
    p1, p99 = np.percentile(img2d, 1), np.percentile(img2d, 99)
    x = (img2d - p1) / (p99 - p1 + 1e-6)
    return np.clip(x, 0, 1)

# Collect external slices
all_vols = [p for p in P158_EXT.rglob("*") if is_volume(p)]
t2_files = [p for p in all_vols if looks_like_t2(p)]
case_folders = sorted({p.parent for p in t2_files})
case_folders = case_folders[:MAX_CASES_EXT]
print(f"\nExternal case folders considered: {len(case_folders)}")

Xext01, yext = [], []
used = 0
for folder in case_folders:
    vols = [p for p in folder.iterdir() if is_volume(p)]
    t2c = [p for p in vols if looks_like_t2(p)]
    if not t2c:
        continue
    t2_path = sorted(t2c, key=lambda x: len(x.name))[0]
    mask_path = pick_lesion_mask(folder, t2_path)
    if mask_path is None:
        continue
    try:
        vol = read_vol(t2_path)
        msk = read_vol(mask_path)
    except Exception:
        continue
    if vol.ndim != 3 or msk.ndim != 3 or vol.shape != msk.shape:
        continue

    pos = np.where(np.sum(msk > 0, axis=(1,2)) > 0)[0].tolist()
    neg = np.where(np.sum(msk > 0, axis=(1,2)) == 0)[0].tolist()
    if len(pos) == 0 or len(neg) == 0:
        continue

    random.shuffle(pos); random.shuffle(neg)
    pos = pos[:POS_SLICES_PER_CASE]
    neg = neg[:NEG_SLICES_PER_CASE]
    for z in pos:
        Xext01.append(slice_to_01(vol[z])); yext.append(1)
    for z in neg:
        Xext01.append(slice_to_01(vol[z])); yext.append(0)
    used += 1

print(f"External cases used: {used}")
print(f"External slices: {len(Xext01)} (pos={sum(yext)}, neg={len(yext)-sum(yext)})")
if len(Xext01) < 30 or len(set(yext)) < 2:
    raise RuntimeError("Not enough external data found. Increase MAX_CASES_EXT or slice counts.")

yext = np.array(yext, dtype=int)

# External eval: Pure classic HOG
def hog_vec_from_img01(img01):
    g = resize(img01.astype(np.float32), (HOG_SIZE, HOG_SIZE), anti_aliasing=True)
    return hog(g, orientations=9, pixels_per_cell=(8,8), cells_per_block=(2,2),
               block_norm="L2-Hys", feature_vector=True)

Hext = np.vstack([hog_vec_from_img01(x) for x in Xext01])
p_hog_ext = hog_svm.predict_proba(Hext)[:,1]
eval_metrics("EXTERNAL PURE_CLASSIC HOG+SVM (thr=0.5)", yext, p_hog_ext, 0.5)

# External eval: ResNet50 embeddings -> LR/SVM
# Build tensors and extract embeddings
def ext_to_50_tensor(img01):
    im = Image.fromarray((img01*255).astype(np.uint8)).convert("L").convert("RGB")
    return preprocess50(im)

Xext_50 = torch.stack([ext_to_50_tensor(x) for x in Xext01], dim=0)

@torch.no_grad()
def feats50_from_tensor(Xtensor, batch=32):
    feats=[]
    for i in range(0, len(Xtensor), batch):
        xb = Xtensor[i:i+batch].to(device)
        feats.append(resnet50_feat(xb).detach().cpu().numpy())
    return np.vstack(feats)

Fext = feats50_from_tensor(Xext_50, batch=32)
p_lr_ext = lr.predict_proba(Fext)[:,1]
p_svm_ext = svm_cal.predict_proba(Fext)[:,1]

eval_metrics("EXTERNAL PRETRAINED+CLASSIC LR (thr=0.5)", yext, p_lr_ext, 0.5)
eval_metrics("EXTERNAL PRETRAINED+CLASSIC SVM (thr=0.5)", yext, p_svm_ext, 0.5)
eval_metrics(f"EXTERNAL PRETRAINED+CLASSIC LR (FN-priority thr={thr_lr:.4f})", yext, p_lr_ext, thr_lr)
eval_metrics(f"EXTERNAL PRETRAINED+CLASSIC SVM (FN-priority thr={thr_svm:.4f})", yext, p_svm_ext, thr_svm)

# ============================================================
# 4) Zip everything in /content for download
# ============================================================
ZIP_OUT = "/content/all_content_results.zip"
subprocess.check_call(["bash", "-lc", f"zip -r {ZIP_OUT} /content -x {ZIP_OUT} /content/sample_data/* > /dev/null"])
print("\nZipped everything to:", ZIP_OUT)
print("You can download it from the Colab file browser.")