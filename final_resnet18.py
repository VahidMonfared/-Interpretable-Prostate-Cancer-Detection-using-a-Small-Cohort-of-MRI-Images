# -*- coding: utf-8 -*-
"""Final ResNet18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fB3qgaQDV8a9ZwwbumTF017dfClfHSRg
"""



!rm -rf /content/*

# ============================================================
# Prostate T2 MRI Cancer Detection (Colab - One Snippet)
# - ResNet18 transfer learning
# - Robust preprocessing (resize/normalize grayscale->3ch)
# - Augmentation (rotation/affine/flip)
# - Class imbalance (WeightedRandomSampler + pos_weight)
# - 80/20 split (train+val via K-fold CV on 80%, separate 20% held-out test)
# - Long early stopping (patience), epochs=100
# - Metrics for Train/Val/Test: Acc, Prec, Recall(Sens), Spec, F1, AUC, TN/FP/FN/TP
# - ROC curves, confusion matrices, train-vs-val curves
# - Grad-CAM: 4x4 grid (16 images) = top-8 high-prob cancer + top-8 high-prob normal
# - Risk stratification (Low/Inter/High), embeddings + UMAP + outlier/“suspicious normals”
# - Save model (.pt) + pickle (.pkl) for web app
# ============================================================

!pip -q install scikit-learn matplotlib opencv-python umap-learn

import os, zipfile, random, math, pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from PIL import Image

from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve
)

import umap
from sklearn.cluster import KMeans

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler
from torchvision import models, transforms

# ----------------------------
# Reproducibility
# ----------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# ----------------------------
# Paths (your zips)
# ----------------------------
CANCER_ZIP = "/content/Cancer.zip"
NORMAL_ZIP = "/content/Normal.zip"
WORKDIR = "/content/data_prostate"
os.makedirs(WORKDIR, exist_ok=True)

def unzip_to_dir(zip_path, out_dir):
    with zipfile.ZipFile(zip_path, 'r') as z:
        z.extractall(out_dir)

unzip_to_dir(CANCER_ZIP, WORKDIR)
unzip_to_dir(NORMAL_ZIP, WORKDIR)

# Expect folder names Cancer and Normal somewhere under WORKDIR.
# If your structure is different, this still scans recursively.
def collect_images(root):
    exts = (".png",".jpg",".jpeg")
    files=[]
    for r,_,fs in os.walk(root):
        for f in fs:
            if f.lower().endswith(exts):
                files.append(os.path.join(r,f))
    return sorted(files)

# Try canonical subfolders first; otherwise scan whole WORKDIR and filter by path token
cancer_dir = os.path.join(WORKDIR, "Cancer")
normal_dir = os.path.join(WORKDIR, "Normal")

if os.path.isdir(cancer_dir) and os.path.isdir(normal_dir):
    cancer_files = collect_images(cancer_dir)
    normal_files = collect_images(normal_dir)
else:
    all_files = collect_images(WORKDIR)
    cancer_files = [p for p in all_files if "cancer" in p.lower()]
    normal_files = [p for p in all_files if "normal" in p.lower()]

print("Cancer images:", len(cancer_files))
print("Normal images:", len(normal_files))

assert len(cancer_files) > 0 and len(normal_files) > 0, "Could not find Cancer/Normal images after unzip."

X = cancer_files + normal_files
y = np.array([1]*len(cancer_files) + [0]*len(normal_files), dtype=int)

# ----------------------------
# Train/Test split: 80/20
# ----------------------------
X_trainval, X_test, y_trainval, y_test = train_test_split(
    X, y, test_size=0.20, random_state=SEED, stratify=y
)
print("\nSplit sizes:")
print("Train+Val:", len(X_trainval), "Test:", len(X_test))
print("Train+Val cancer:", y_trainval.sum(), "normal:", len(y_trainval)-y_trainval.sum())
print("Test cancer:", y_test.sum(), "normal:", len(y_test)-y_test.sum())

# ----------------------------
# Dataset + Transforms
# - images are grayscale; convert to 3 channels for ResNet
# - resize to fixed size
# ----------------------------
IMG_SIZE = 224

tf_train = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomRotation(10),
    transforms.RandomAffine(degrees=0, translate=(0.03,0.03), scale=(0.95,1.05)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.485,0.485], [0.229,0.229,0.229]),
])

tf_eval = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.485,0.485], [0.229,0.229,0.229]),
])

class ProstateDataset(Dataset):
    def __init__(self, paths, labels, transform):
        self.paths = list(paths)
        self.labels = np.array(labels, dtype=int)
        self.transform = transform
    def __len__(self):
        return len(self.paths)
    def __getitem__(self, idx):
        p = self.paths[idx]
        img = Image.open(p).convert("L")
        x = self.transform(img)
        y = torch.tensor(self.labels[idx], dtype=torch.float32)
        return x, y, p

# Global test dataset/loader (fixed)
ds_test = ProstateDataset(X_test, y_test, tf_eval)

# ----------------------------
# Model: ResNet18 transfer learning
# ----------------------------
def build_resnet18(dropout=0.35, freeze_backbone=False):
    m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    if freeze_backbone:
        for name, param in m.named_parameters():
            if not name.startswith("fc."):
                param.requires_grad = False
    in_f = m.fc.in_features
    m.fc = nn.Sequential(
        nn.Dropout(dropout),
        nn.Linear(in_f, 1)
    )
    return m.to(device)

# ----------------------------
# Metrics helpers
# ----------------------------
def compute_metrics(y_true, y_prob, thr=0.5):
    y_true = np.array(y_true).astype(int)
    y_prob = np.array(y_prob).astype(float)
    y_pred = (y_prob >= thr).astype(int)

    cm = confusion_matrix(y_true, y_pred, labels=[0,1])
    tn, fp, fn, tp = cm.ravel()

    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, zero_division=0)
    rec = recall_score(y_true, y_pred, zero_division=0)   # sensitivity
    f1 = f1_score(y_true, y_pred, zero_division=0)
    spec = tn / (tn + fp + 1e-12)

    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else float("nan")

    return {
        "acc": acc, "prec": prec, "recall": rec, "spec": spec, "f1": f1, "auc": auc,
        "tn": tn, "fp": fp, "fn": fn, "tp": tp, "cm": cm
    }

def plot_confusion(cm, title):
    plt.figure(figsize=(4.3,3.7))
    plt.imshow(cm)
    plt.title(title)
    plt.colorbar()
    plt.xticks([0,1], ["Normal","Cancer"])
    plt.yticks([0,1], ["Normal","Cancer"])
    for i in range(2):
        for j in range(2):
            plt.text(j,i,str(cm[i,j]),ha="center",va="center")
    plt.xlabel("Pred"); plt.ylabel("True")
    plt.tight_layout(); plt.show()

def plot_roc_curve(y_true, y_prob, title):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true))>1 else float("nan")
    plt.figure(figsize=(4.5,3.8))
    plt.plot(fpr, tpr, label=f"AUC={auc:.3f}")
    plt.plot([0,1], [0,1], "--")
    plt.title(title); plt.xlabel("FPR"); plt.ylabel("TPR")
    plt.legend(); plt.tight_layout(); plt.show()

def plot_train_val_curves(history, title):
    ep = np.arange(1, len(history["train_loss"])+1)
    plt.figure(figsize=(6,4))
    plt.plot(ep, history["train_loss"], label="Train loss")
    plt.plot(ep, history["val_loss"], label="Val loss")
    plt.title(title+" - Loss"); plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.tight_layout(); plt.show()

    plt.figure(figsize=(6,4))
    plt.plot(ep, history["train_acc"], label="Train acc")
    plt.plot(ep, history["val_acc"], label="Val acc")
    plt.title(title+" - Accuracy"); plt.xlabel("Epoch"); plt.ylabel("Accuracy")
    plt.legend(); plt.tight_layout(); plt.show()

# ----------------------------
# Training/Eval loops
# ----------------------------
@torch.no_grad()
def predict_probs(model, loader):
    model.eval()
    probs = []
    ys = []
    paths = []
    for x,y,p in loader:
        x = x.to(device)
        logits = model(x)
        pr = torch.sigmoid(logits).detach().cpu().numpy().ravel()
        probs.extend(pr.tolist())
        ys.extend(y.numpy().astype(int).ravel().tolist())
        paths.extend(list(p))
    return np.array(ys), np.array(probs), paths

def make_weighted_sampler(y_labels):
    y_labels = np.array(y_labels, dtype=int)
    counts = np.bincount(y_labels, minlength=2)
    class_w = 1.0 / (counts + 1e-12)
    sample_w = class_w[y_labels]
    sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)
    return sampler, counts

def train_one_fold(
    fold_id, train_idx, val_idx, X_tv, y_tv,
    epochs=100, batch_size=16, lr=1e-4, wd=1e-3,
    dropout=0.35, patience=20, min_delta=1e-4
):
    # Datasets per fold
    X_tr = [X_tv[i] for i in train_idx]
    y_tr = [y_tv[i] for i in train_idx]
    X_va = [X_tv[i] for i in val_idx]
    y_va = [y_tv[i] for i in val_idx]

    ds_tr = ProstateDataset(X_tr, y_tr, tf_train)
    ds_va = ProstateDataset(X_va, y_va, tf_eval)

    sampler, counts = make_weighted_sampler(y_tr)
    pos_weight = torch.tensor([counts[0]/max(counts[1],1)], dtype=torch.float32).to(device)

    dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)
    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)

    model = build_resnet18(dropout=dropout, freeze_backbone=False)
    crit = nn.BCEWithLogitsLoss(pos_weight=pos_weight)

    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)

    history = {"train_loss":[], "val_loss":[], "train_acc":[], "val_acc":[]}

    best_auc = -1
    best_state = None
    best_epoch = 0
    bad = 0

    print(f"\n========== Fold {fold_id} ==========")
    print("Train counts [normal,cancer]:", counts, "pos_weight:", float(pos_weight.item()))

    for ep in range(1, epochs+1):
        model.train()
        tr_losses=[]
        tr_probs=[]
        tr_true=[]

        for x,y,_ in dl_tr:
            x = x.to(device)
            y = y.to(device).unsqueeze(1)

            opt.zero_grad()
            logits = model(x)
            loss = crit(logits, y)
            loss.backward()
            opt.step()

            tr_losses.append(loss.item())
            tr_probs.extend(torch.sigmoid(logits).detach().cpu().numpy().ravel().tolist())
            tr_true.extend(y.detach().cpu().numpy().ravel().astype(int).tolist())

        model.eval()
        va_losses=[]
        va_probs=[]
        va_true=[]
        with torch.no_grad():
            for x,y,_ in dl_va:
                x = x.to(device)
                y = y.to(device).unsqueeze(1)
                logits = model(x)
                loss = crit(logits, y)
                va_losses.append(loss.item())
                va_probs.extend(torch.sigmoid(logits).cpu().numpy().ravel().tolist())
                va_true.extend(y.cpu().numpy().ravel().astype(int).tolist())

        tr_m = compute_metrics(tr_true, tr_probs, thr=0.5)
        va_m = compute_metrics(va_true, va_probs, thr=0.5)

        history["train_loss"].append(float(np.mean(tr_losses)))
        history["val_loss"].append(float(np.mean(va_losses)))
        history["train_acc"].append(tr_m["acc"])
        history["val_acc"].append(va_m["acc"])

        print(f"Ep {ep:03d} | "
              f"Tr loss {np.mean(tr_losses):.4f} acc {tr_m['acc']:.3f} auc {tr_m['auc']:.3f} | "
              f"Va loss {np.mean(va_losses):.4f} acc {va_m['acc']:.3f} auc {va_m['auc']:.3f}")

        # Early stopping on VAL AUC (long patience)
        improved = (va_m["auc"] > best_auc + min_delta)
        if improved:
            best_auc = va_m["auc"]
            best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}
            best_epoch = ep
            bad = 0
        else:
            bad += 1

        if bad >= patience:
            print(f"Early stopping triggered at epoch {ep} (best epoch {best_epoch}, best val AUC {best_auc:.4f})")
            break

    # restore best
    model.load_state_dict(best_state)
    return model, history, (ds_tr, ds_va), best_auc

# ----------------------------
# Cross-validation on Train+Val (80%)
# ----------------------------
K = 5  # you can set 3 or 5; 5 is typical for small data
skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)

fold_models = []
fold_histories = []
fold_val_aucs = []

X_tv = list(X_trainval)
y_tv = np.array(y_trainval, dtype=int)

for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_tv, y_tv), start=1):
    model, history, (ds_tr, ds_va), best_auc = train_one_fold(
        fold_id, tr_idx, va_idx, X_tv, y_tv,
        epochs=100, batch_size=16, lr=1e-4, wd=1e-3,
        dropout=0.35, patience=25, min_delta=1e-4  # long early stopping
    )
    fold_models.append((model, ds_tr, ds_va))
    fold_histories.append(history)
    fold_val_aucs.append(best_auc)

print("\nCV val AUCs:", [float(x) for x in fold_val_aucs])
best_fold = int(np.argmax(fold_val_aucs))
print("Best fold:", best_fold+1, "Best val AUC:", float(fold_val_aucs[best_fold]))

# Plot curves for best fold
plot_train_val_curves(fold_histories[best_fold], f"Best Fold {best_fold+1} Train vs Val")

best_model, best_ds_tr, best_ds_va = fold_models[best_fold]

# ----------------------------
# Final evaluation: Train / Val (from best fold) / Test
# ----------------------------
dl_tr_best = DataLoader(best_ds_tr, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)
dl_va_best = DataLoader(best_ds_va, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)
dl_test = DataLoader(ds_test, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)

y_tr_true, y_tr_prob, tr_paths = predict_probs(best_model, dl_tr_best)
y_va_true, y_va_prob, va_paths = predict_probs(best_model, dl_va_best)
y_te_true, y_te_prob, te_paths = predict_probs(best_model, dl_test)

m_tr = compute_metrics(y_tr_true, y_tr_prob)
m_va = compute_metrics(y_va_true, y_va_prob)
m_te = compute_metrics(y_te_true, y_te_prob)

print("\n=== BEST FOLD TRAIN ===\n", m_tr)
print("\n=== BEST FOLD VAL ===\n", m_va)
print("\n=== HELD-OUT TEST (20%) ===\n", m_te)

# Confusion matrices + ROC curves
plot_confusion(m_tr["cm"], "Train Confusion Matrix (best fold)")
plot_roc_curve(y_tr_true, y_tr_prob, "Train ROC (best fold)")

plot_confusion(m_va["cm"], "Val Confusion Matrix (best fold)")
plot_roc_curve(y_va_true, y_va_prob, "Val ROC (best fold)")

plot_confusion(m_te["cm"], "Test Confusion Matrix (20% held-out)")
plot_roc_curve(y_te_true, y_te_prob, "Test ROC (20% held-out)")

# Summary table (Train/Val/Test)
summary = pd.DataFrame([
    ["Train", m_tr["acc"], m_tr["prec"], m_tr["recall"], m_tr["spec"], m_tr["f1"], m_tr["auc"], m_tr["tn"], m_tr["fp"], m_tr["fn"], m_tr["tp"]],
    ["Val",   m_va["acc"], m_va["prec"], m_va["recall"], m_va["spec"], m_va["f1"], m_va["auc"], m_va["tn"], m_va["fp"], m_va["fn"], m_va["tp"]],
    ["Test",  m_te["acc"], m_te["prec"], m_te["recall"], m_te["spec"], m_te["f1"], m_te["auc"], m_te["tn"], m_te["fp"], m_te["fn"], m_te["tp"]],
], columns=["Split","Acc","Prec","Recall(Sens)","Spec","F1","AUC","TN","FP","FN","TP"])
print("\n=== METRICS TABLE (Best Fold Model) ===")
summary

# ============================================================
# Grad-CAM Implementation (ResNet18)
# - Produces 4x4 = 16 images: 8 top-prob cancers + 8 top-prob normals
# ============================================================

def denorm_tensor(x):
    mean = torch.tensor([0.485,0.485,0.485]).view(3,1,1)
    std  = torch.tensor([0.229,0.229,0.229]).view(3,1,1)
    x = x.detach().cpu() * std + mean
    return x.clamp(0,1)

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.layer = target_layer
        self.gradients = None
        self.activations = None
        self.hook_a = self.layer.register_forward_hook(self._forward_hook)
        self.hook_g = self.layer.register_full_backward_hook(self._backward_hook)

    def _forward_hook(self, module, inp, out):
        self.activations = out

    def _backward_hook(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def remove(self):
        self.hook_a.remove()
        self.hook_g.remove()

    def __call__(self, x):
        # x: (1,3,H,W)
        self.model.zero_grad()
        logits = self.model(x)
        score = logits.squeeze()
        score.backward(retain_graph=True)

        grads = self.gradients  # (1,C,h,w)
        acts = self.activations # (1,C,h,w)

        weights = grads.mean(dim=(2,3), keepdim=True)  # (1,C,1,1)
        cam = (weights * acts).sum(dim=1, keepdim=True)  # (1,1,h,w)
        cam = F.relu(cam)

        cam = F.interpolate(cam, size=(IMG_SIZE, IMG_SIZE), mode="bilinear", align_corners=False)
        cam = cam.squeeze().detach().cpu().numpy()
        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)
        return cam

# Create an eval dataset for test+val+trainval examples (for visualization)
ds_all_for_cam = ProstateDataset(X_test, y_test, tf_eval)  # using test set examples
dl_all_for_cam = DataLoader(ds_all_for_cam, batch_size=1, shuffle=False)

# Get probabilities for ALL test items
best_model.eval()
all_probs=[]
all_labels=[]
all_paths=[]
all_imgs=[]
with torch.no_grad():
    for x,y,p in dl_all_for_cam:
        x = x.to(device)
        pr = torch.sigmoid(best_model(x)).item()
        all_probs.append(pr)
        all_labels.append(int(y.item()))
        all_paths.append(p[0])
        all_imgs.append(x.detach().cpu())

all_probs = np.array(all_probs)
all_labels = np.array(all_labels)

# Select TOP 8 cancer probs among y=1 and TOP 8 normal probs among y=0 (high confidence)
c_idx = np.where(all_labels==1)[0]
n_idx = np.where(all_labels==0)[0]

top_c = c_idx[np.argsort(-all_probs[c_idx])][:8] if len(c_idx)>0 else []
top_n = n_idx[np.argsort(all_probs[n_idx])][:8]  if len(n_idx)>0 else []  # normals: smallest prob

selected = list(top_c) + list(top_n)
print("\nGrad-CAM selection (from TEST):")
print("Top-8 cancer indices:", list(top_c))
print("Top-8 normal indices:", list(top_n))

# Setup Grad-CAM on last conv block (layer4)
cam_extractor = GradCAM(best_model, best_model.layer4)

def overlay_cam(img_tensor, cam, alpha=0.45):
    # img_tensor: (3,224,224) normalized; denorm for display
    img = denorm_tensor(img_tensor).numpy().transpose(1,2,0)  # (H,W,3)
    # overlay using matplotlib colormap
    heat = plt.get_cmap("jet")(cam)[:,:,:3]  # (H,W,3)
    out = (1-alpha)*img + alpha*heat
    out = np.clip(out, 0, 1)
    return out

# Plot 4x4 grid: 16 images
plt.figure(figsize=(14,10))
for i, idx in enumerate(selected[:16]):
    x = all_imgs[idx].squeeze(0).unsqueeze(0).to(device)  # (1,3,224,224)
    y_true = all_labels[idx]
    p_hat = all_probs[idx]

    cam = cam_extractor(x)
    x0 = all_imgs[idx].squeeze(0)  # (3,224,224)
    ov = overlay_cam(x0, cam)

    plt.subplot(4,4,i+1)
    plt.imshow(ov)
    plt.title(f"y={y_true}, p={p_hat:.2f}")
    plt.axis("off")

plt.suptitle("Grad-CAM (4x4): Top-8 Cancer (high p) + Top-8 Normal (low p) from TEST", fontsize=14)
plt.tight_layout()
plt.show()

cam_extractor.remove()

# ============================================================
# Risk Stratification & Hidden Cancer Discovery
# - Embeddings from penultimate layer (fc input) using forward hook
# - UMAP visualization + clustering
# - Suspicious normals: y=0 but high predicted p
# ============================================================

# Hook to capture penultimate features (output of avgpool flatten before fc)
# For torchvision resnet18, features are produced before `fc` after `avgpool`.
embeddings = []
labels_all = []
probs_all = []
paths_all = []

def hook_fn(module, inp, out):
    # out shape from avgpool is (B,512,1,1) typically
    feat = out.detach().cpu().numpy()
    feat = feat.reshape(feat.shape[0], -1)  # (B,512)
    embeddings.append(feat)

handle = best_model.avgpool.register_forward_hook(hook_fn)

# Use full TrainVal (80%) + Test (20%) to analyze embeddings
X_full = X_trainval + X_test
y_full = np.concatenate([y_trainval, y_test], axis=0)
ds_full = ProstateDataset(X_full, y_full, tf_eval)
dl_full = DataLoader(ds_full, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)

best_model.eval()
with torch.no_grad():
    for x,y,p in dl_full:
        x = x.to(device)
        logits = best_model(x)
        pr = torch.sigmoid(logits).cpu().numpy().ravel()
        probs_all.extend(pr.tolist())
        labels_all.extend(y.numpy().astype(int).ravel().tolist())
        paths_all.extend(list(p))

handle.remove()

E = np.vstack(embeddings)
labels_all = np.array(labels_all, dtype=int)
probs_all = np.array(probs_all, dtype=float)

# Risk bins
def risk_bin(p):
    if p < 0.33: return "Low"
    if p < 0.66: return "Intermediate"
    return "High"

risk_all = np.array([risk_bin(p) for p in probs_all])

# UMAP projection
reducer = umap.UMAP(n_neighbors=10, min_dist=0.1, random_state=SEED)
Z = reducer.fit_transform(E)

# Clustering in embedding space
kmeans = KMeans(n_clusters=3, random_state=SEED, n_init="auto").fit(Z)
clusters = kmeans.labels_

# Suspicious normals (normal-labeled but high cancer probability)
sus_idx = np.where((labels_all==0) & (probs_all>=0.66))[0]
print("\n=== Suspicious NORMALs (y=0, but p>=0.66) ===")
if len(sus_idx)==0:
    print("None found with p>=0.66. (You can lower threshold to 0.55 if needed.)")
else:
    for i in sus_idx[:15]:
        print(f"p={probs_all[i]:.3f}, risk={risk_all[i]}, cluster={clusters[i]}, path={paths_all[i]}")

# Borderline cases: probabilities near 0.5
border_idx = np.where((probs_all>0.45) & (probs_all<0.55))[0]
print("\n=== Borderline cases (0.45 < p < 0.55) ===")
for i in border_idx[:15]:
    print(f"y={labels_all[i]}, p={probs_all[i]:.3f}, risk={risk_all[i]}, path={paths_all[i]}")

# Plot UMAP colored by true label
plt.figure(figsize=(6,5))
plt.scatter(Z[:,0], Z[:,1], c=labels_all)
plt.title("UMAP of Embeddings - colored by TRUE label (0=Normal,1=Cancer)")
plt.tight_layout(); plt.show()

# Plot UMAP colored by predicted risk
risk_to_num = {"Low":0, "Intermediate":1, "High":2}
plt.figure(figsize=(6,5))
plt.scatter(Z[:,0], Z[:,1], c=[risk_to_num[r] for r in risk_all])
plt.title("UMAP of Embeddings - colored by PREDICTED risk (Low/Inter/High)")
plt.tight_layout(); plt.show()

# ============================================================
# Save Model for reuse
# - Torch weights (.pt)
# - Full model object in pickle (.pkl) for web app (note: requires same code at load time)
#   Better for web: save state_dict + rebuild architecture at inference.
# ============================================================

MODEL_PT = "/content/prostate_resnet18_bestfold.pt"
MODEL_PKL = "/content/prostate_resnet18_bestfold.pkl"

torch.save(best_model.state_dict(), MODEL_PT)

# pickle full model (works if torch version/architecture matches at load)
with open(MODEL_PKL, "wb") as f:
    pickle.dump(best_model.cpu(), f)

# move back to device for session use
best_model.to(device)

print("\nSaved:")
print(MODEL_PT)
print(MODEL_PKL)

pickle.dump(best_model.state_dict(), open("/content/prostate_resnet18_light.pkl","wb"), protocol=pickle.HIGHEST_PROTOCOL)


# OPTIONAL: print the final table again clearly
print("\n=== FINAL METRICS TABLE ===")
display(summary)

!zip -r /content/colab_all_content.zip /content && from google.colab import files
files.download("/content/colab_all_content.zip")