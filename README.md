Prostate cancer is a leading cause of death in men, and accurate MRI-based detection can dramatically improve outcomes. However, interpreting T2-weighted prostate MRI is challenging because cancerous lesions vary in appearance, making manual diagnosis error-prone. We developed an interpretable AI system for automatic cancer detection using only 162 T2-weighted images (102 cancer, 60 normal)â€”addressing small dataset and class imbalance challenges through transfer learning and data augmentation.
We conducted the first comprehensive comparison of Vision Transformers (ViT, Swin) versus CNNs (ResNet18) and classical methods (Logistic Regression, SVM, HOG+SVM) on prostate MRI. Transfer-learned ResNet18 achieved best performance (90.9% accuracy, 95% sensitivity), while Vision Transformers underperformed (81-82%). Surprisingly, classical HOG+SVM matched ResNet18's accuracy, proving handcrafted features can compete with deep learning on small datasets. All models showed excellent discrimination (AUC 0.90-0.94).
Unlike state-of-the-art models requiring thousands of images and multi-parametric sequences, our lightweight ResNet18 (11M parameters) delivers competitive results with minimal resources. Using Grad-CAM, UMAP, and attention maps, we visualized model decision-making for detection and surgical planning, confirming anatomically relevant focus. External validation on Prostate158 revealed domain shift challenges, motivating future work on multi-center training with harmonized preprocessing and self-/semi-supervised pretraining for real-world deployment.
