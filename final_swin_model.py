# -*- coding: utf-8 -*-
"""Final Swin Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YC9yrBmUOdyxWBsiClIbp6B9cM6ReTCT
"""

# !rm -rf /content/*

# ============================================================
# Prostate T2 MRI Cancer Detection â€” SWIN TRANSFORMER (100% COMPLETE)
# One Colab snippet that PRINTS/DISPLAYS EVERYTHING you listed:
# 1) Device info
# 2) Cancer/Normal counts after unzip
# 3) 80/20 split sizes + class counts
# 4) Per-fold headers (counts + pos_weight)
# 5) Per-epoch logs (loss, acc, AUC)
# 6) Early stopping (best epoch + best AUC)
# 7) CV AUC list + best fold
# 8) Best-fold train-vs-val curves (loss+acc)
# 9) Final metrics dicts for Train/Val/Test
# 10) Confusion heatmaps for Train/Val/Test
# 11) ROC curves for Train/Val/Test
# 12) Metrics summary table for Train/Val/Test
# 13) Swin Grad-CAM-like attention (true Grad-CAM on last feature map) 4x4 grid
# 14) Printed indices used for attention
# 15) Suspicious normals (y=0 but high p)
# 16) Borderline cases (near 0.5)
# 17) UMAP of Swin embeddings colored by true labels
# 18) UMAP colored by predicted risk
# 19) Saved model paths (.pt + .pkl)
# ============================================================

!pip -q install timm umap-learn scikit-learn matplotlib opencv-python

import os, zipfile, random, pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve
)

import umap
from sklearn.cluster import KMeans

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torchvision import transforms

import timm

# -------------------- Reproducibility --------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)
print("torch:", torch.__version__)
print("timm:", timm.__version__)

# -------------------- Paths --------------------
CANCER_ZIP = "/content/Cancer.zip"
NORMAL_ZIP = "/content/Normal.zip"
ROOT = "/content/data_swin_full"
os.makedirs(ROOT, exist_ok=True)

def unzip(z, out):
    with zipfile.ZipFile(z) as f:
        f.extractall(out)

unzip(CANCER_ZIP, ROOT)
unzip(NORMAL_ZIP, ROOT)

def collect(root):
    out=[]
    for r,_,fs in os.walk(root):
        for f in fs:
            if f.lower().endswith((".png",".jpg",".jpeg")):
                out.append(os.path.join(r,f))
    return sorted(out)

all_paths = collect(ROOT)

cancer = [p for p in all_paths if "cancer" in p.lower()]
normal = [p for p in all_paths if "normal" in p.lower()]

print("\nAfter unzip + scan:")
print("Cancer images:", len(cancer))
print("Normal images:", len(normal))

if len(cancer) == 0 or len(normal) == 0:
    raise ValueError(
        f"Could not find both classes. Found cancer={len(cancer)} normal={len(normal)}.\n"
        "Make sure extracted paths include 'cancer' and 'normal' in folder/file names."
    )

X = cancer + normal
y = np.array([1]*len(cancer) + [0]*len(normal), dtype=int)
print("Total images:", len(X), "| Cancer:", int((y==1).sum()), "| Normal:", int((y==0).sum()))

# -------------------- 80/20 Split --------------------
X_tv, X_test, y_tv, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=SEED
)

print("\nSplit sizes (80/20):")
print("Train+Val:", len(X_tv), "Test:", len(X_test))
print("Train+Val cancer:", int(y_tv.sum()), "normal:", int(len(y_tv)-y_tv.sum()))
print("Test cancer:", int(y_test.sum()), "normal:", int(len(y_test)-y_test.sum()))

# -------------------- Dataset --------------------
IMG = 224

tf_train = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((IMG,IMG)),
    transforms.RandomRotation(10),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

tf_eval = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((IMG,IMG)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

class ProstateDS(Dataset):
    def __init__(self, X, y, tf):
        self.X = list(X)
        self.y = np.array(y, dtype=np.float32)
        self.tf = tf
    def __len__(self): return len(self.X)
    def __getitem__(self,i):
        img = Image.open(self.X[i]).convert("L")
        x = self.tf(img)
        y = torch.tensor(self.y[i], dtype=torch.float32)
        return x, y, self.X[i]

# -------------------- Model (feature-map Swin so Grad-CAM works) --------------------
class SwinBinaryCAM(nn.Module):
    """
    Uses timm Swin backbone in features_only mode to expose a spatial feature map (B,C,H,W),
    enabling true Grad-CAM on the last stage.
    """
    def __init__(self, model_name="swin_base_patch4_window7_224", drop=0.4, out_index=3):
        super().__init__()
        self.backbone = timm.create_model(
            model_name,
            pretrained=True,
            features_only=True,
            out_indices=(out_index,)
        )
        # Determine channel count from a dummy forward
        with torch.no_grad():
            dummy = torch.zeros(1,3,IMG,IMG)
            feat = self.backbone(dummy)[0]
            c = feat.shape[1]
        self.num_features = c

        self.pool = nn.AdaptiveAvgPool2d((1,1))
        self.head = nn.Sequential(
            nn.Dropout(drop),
            nn.Linear(self.num_features, 1)
        )

    def forward(self, x):
        feat = self.backbone(x)[0]          # (B,C,H,W)
        emb = self.pool(feat).flatten(1)    # (B,C)
        logits = self.head(emb)             # (B,1)
        return logits, emb, feat

# -------------------- Metrics --------------------
def compute_metrics(y_true, p_prob, thr=0.5):
    y_true = np.array(y_true).astype(int).ravel()
    p_prob = np.array(p_prob).astype(float).ravel()
    y_pred = (p_prob >= thr).astype(int)

    cm = confusion_matrix(y_true, y_pred, labels=[0,1])
    tn, fp, fn, tp = cm.ravel()

    spec = tn / (tn + fp + 1e-12)
    auc = roc_auc_score(y_true, p_prob) if len(np.unique(y_true)) > 1 else float("nan")

    return {
        "acc": accuracy_score(y_true, y_pred),
        "prec": precision_score(y_true, y_pred, zero_division=0),
        "recall": recall_score(y_true, y_pred, zero_division=0),
        "spec": spec,
        "f1": f1_score(y_true, y_pred, zero_division=0),
        "auc": auc,
        "tn": tn, "fp": fp, "fn": fn, "tp": tp,
        "cm": cm
    }

# -------------------- Plot helpers --------------------
def plot_confusion(cm, title):
    plt.figure(figsize=(4.3,3.7))
    plt.imshow(cm)
    plt.title(title)
    plt.colorbar()
    plt.xticks([0,1], ["Normal","Cancer"])
    plt.yticks([0,1], ["Normal","Cancer"])
    for i in range(2):
        for j in range(2):
            plt.text(j,i,str(cm[i,j]),ha="center",va="center")
    plt.xlabel("Pred"); plt.ylabel("True")
    plt.tight_layout(); plt.show()

def plot_roc_curve(y_true, y_prob, title):
    y_true = np.array(y_true).astype(int)
    y_prob = np.array(y_prob).astype(float)
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else float("nan")
    plt.figure(figsize=(4.5,3.8))
    plt.plot(fpr, tpr, label=f"AUC={auc:.3f}")
    plt.plot([0,1], [0,1], "--")
    plt.title(title); plt.xlabel("FPR"); plt.ylabel("TPR")
    plt.legend(); plt.tight_layout(); plt.show()

def plot_train_val_curves(history, title):
    ep = np.arange(1, len(history["tr_loss"])+1)

    plt.figure(figsize=(6,4))
    plt.plot(ep, history["tr_loss"], label="Train loss")
    plt.plot(ep, history["va_loss"], label="Val loss")
    plt.title(title+" - Loss"); plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.tight_layout(); plt.show()

    plt.figure(figsize=(6,4))
    plt.plot(ep, history["tr_acc"], label="Train acc")
    plt.plot(ep, history["va_acc"], label="Val acc")
    plt.title(title+" - Accuracy"); plt.xlabel("Epoch"); plt.ylabel("Accuracy")
    plt.legend(); plt.tight_layout(); plt.show()

# -------------------- Sampler --------------------
def make_balanced_sampler(y_fold):
    y_fold = np.array(y_fold).astype(int)
    counts = np.bincount(y_fold, minlength=2)
    if counts.min() == 0:
        return None, counts
    class_weights = 1.0 / (counts + 1e-12)
    sample_weights = class_weights[y_fold]
    sampler = WeightedRandomSampler(
        weights=torch.tensor(sample_weights, dtype=torch.double),
        num_samples=len(sample_weights),
        replacement=True
    )
    return sampler, counts

# -------------------- Train one fold --------------------
def train_fold(fid, tr_idx, va_idx, max_epochs=100, patience=25, min_delta=1e-4):
    X_tr = [X_tv[i] for i in tr_idx]
    y_tr = y_tv[tr_idx]
    X_va = [X_tv[i] for i in va_idx]
    y_va = y_tv[va_idx]

    ds_tr = ProstateDS(X_tr, y_tr, tf_train)
    ds_va = ProstateDS(X_va, y_va, tf_eval)

    sampler, cnt = make_balanced_sampler(y_tr)
    dl_tr = DataLoader(ds_tr, batch_size=16, sampler=sampler, shuffle=(sampler is None), num_workers=2, pin_memory=True)
    dl_va = DataLoader(ds_va, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)

    pos_weight = torch.tensor([cnt[0] / max(cnt[1], 1)], dtype=torch.float32).to(device)

    model = SwinBinaryCAM(drop=0.4).to(device)

    opt = torch.optim.AdamW(
        model.parameters(),
        lr=3e-5,
        betas=(0.9, 0.999),
        eps=1e-8,
        weight_decay=1e-3
    )

    lossf = nn.BCEWithLogitsLoss(pos_weight=pos_weight)

    best_score = -1
    best_state = None
    best_epoch = 0
    bad = 0

    hist = {"tr_loss": [], "va_loss": [], "tr_acc": [], "va_acc": [], "tr_auc": [], "va_auc": []}

    print(f"\n========== Fold {fid} ==========")
    print(f"Train counts: normal={cnt[0]} cancer={cnt[1]} | pos_weight={pos_weight.item():.3f}")

    for ep in range(1, max_epochs+1):
        # ---- Train ----
        model.train()
        tl = 0.0
        tr_probs, tr_true = [], []

        for x, yb, _ in dl_tr:
            x = x.to(device, non_blocking=True)
            yb = yb.to(device, non_blocking=True).unsqueeze(1)

            opt.zero_grad(set_to_none=True)
            logits, _, _ = model(x)
            loss = lossf(logits, yb)
            loss.backward()
            opt.step()

            tl += loss.item()
            tr_probs += torch.sigmoid(logits).detach().cpu().numpy().ravel().tolist()
            tr_true  += yb.detach().cpu().numpy().ravel().tolist()

        tr_m = compute_metrics(tr_true, tr_probs)

        # ---- Val ----
        model.eval()
        vl = 0.0
        va_probs, va_true = [], []
        with torch.no_grad():
            for x, yb, _ in dl_va:
                x = x.to(device, non_blocking=True)
                yb = yb.to(device, non_blocking=True).unsqueeze(1)

                logits, _, _ = model(x)
                loss = lossf(logits, yb)
                vl += loss.item()

                va_probs += torch.sigmoid(logits).cpu().numpy().ravel().tolist()
                va_true  += yb.cpu().numpy().ravel().tolist()

        va_m = compute_metrics(va_true, va_probs)

        hist["tr_loss"].append(float(tl))
        hist["va_loss"].append(float(vl))
        hist["tr_acc"].append(float(tr_m["acc"]))
        hist["va_acc"].append(float(va_m["acc"]))
        hist["tr_auc"].append(float(tr_m["auc"]))
        hist["va_auc"].append(float(va_m["auc"]))

        print(
            f"Ep {ep:03d} | "
            f"Tr loss {tl:.4f} acc {tr_m['acc']:.3f} auc {tr_m['auc']:.3f} | "
            f"Va loss {vl:.4f} acc {va_m['acc']:.3f} auc {va_m['auc']:.3f}"
        )

        score = va_m["auc"]
        if score > best_score + min_delta:
            best_score = score
            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}
            best_epoch = ep
            bad = 0
        else:
            bad += 1

        if bad >= patience:
            print(f"Early stopping triggered at epoch {ep} (best epoch {best_epoch}, best val AUC {best_score:.4f})")
            break

    if best_state is None:
        best_state = model.state_dict()

    model.load_state_dict(best_state)
    return model, hist, best_score, (tr_idx, va_idx)

# -------------------- Cross-validation --------------------
K = 3
skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)

fold_models = []
fold_hists  = []
fold_aucs   = []
fold_splits = []

for fid, (tr_idx, va_idx) in enumerate(skf.split(X_tv, y_tv), start=1):
    m, h, a, split = train_fold(fid, tr_idx, va_idx, max_epochs=100, patience=25, min_delta=1e-4)
    fold_models.append(m)
    fold_hists.append(h)
    fold_aucs.append(a)
    fold_splits.append(split)

print("\nCV val AUCs:", [float(x) for x in fold_aucs])
best_fold = int(np.argmax(fold_aucs))
print("Best fold:", best_fold+1, "Best val AUC:", float(fold_aucs[best_fold]))

# Best fold training curves
plot_train_val_curves(fold_hists[best_fold], f"Best Fold {best_fold+1} Train vs Val")

best_model = fold_models[best_fold].to(device)
best_tr_idx, best_va_idx = fold_splits[best_fold]
best_X_tr = [X_tv[i] for i in best_tr_idx]
best_y_tr = y_tv[best_tr_idx]
best_X_va = [X_tv[i] for i in best_va_idx]
best_y_va = y_tv[best_va_idx]

ds_tr_best = ProstateDS(best_X_tr, best_y_tr, tf_eval)
ds_va_best = ProstateDS(best_X_va, best_y_va, tf_eval)
ds_te      = ProstateDS(X_test, y_test, tf_eval)

# -------------------- Predict helpers (probs + embeddings) --------------------
@torch.no_grad()
def predict_probs_embs(model, ds, batch_size=16):
    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
    model.eval()
    probs, ys, paths, embs = [], [], [], []
    for x, yb, p in dl:
        x = x.to(device, non_blocking=True)
        logits, emb, _ = model(x)
        pr = torch.sigmoid(logits).cpu().numpy().ravel()
        probs.extend(pr.tolist())
        ys.extend(yb.numpy().astype(int).ravel().tolist())
        paths.extend(list(p))
        embs.append(emb.cpu().numpy())
    embs = np.vstack(embs) if len(embs) else np.zeros((0,1))
    return np.array(ys), np.array(probs), paths, embs

y_tr_true, y_tr_prob, tr_paths, tr_emb = predict_probs_embs(best_model, ds_tr_best)
y_va_true, y_va_prob, va_paths, va_emb = predict_probs_embs(best_model, ds_va_best)
y_te_true, y_te_prob, te_paths, te_emb = predict_probs_embs(best_model, ds_te)

m_tr = compute_metrics(y_tr_true, y_tr_prob)
m_va = compute_metrics(y_va_true, y_va_prob)
m_te = compute_metrics(y_te_true, y_te_prob)

# 9) Final performance dictionaries
print("\n=== BEST FOLD TRAIN ===\n", m_tr)
print("\n=== BEST FOLD VAL ===\n", m_va)
print("\n=== HELD-OUT TEST (20%) ===\n", m_te)

# 10) Confusion matrix heatmaps
plot_confusion(m_tr["cm"], "Train Confusion Matrix (best fold)")
plot_confusion(m_va["cm"], "Val Confusion Matrix (best fold)")
plot_confusion(m_te["cm"], "Test Confusion Matrix (20% held-out)")

# 11) ROC curves
plot_roc_curve(y_tr_true, y_tr_prob, "Train ROC (best fold)")
plot_roc_curve(y_va_true, y_va_prob, "Val ROC (best fold)")
plot_roc_curve(y_te_true, y_te_prob, "Test ROC (20% held-out)")

# 12) Metrics summary table
summary = pd.DataFrame([
    ["Train", m_tr["acc"], m_tr["prec"], m_tr["recall"], m_tr["spec"], m_tr["f1"], m_tr["auc"], m_tr["tn"], m_tr["fp"], m_tr["fn"], m_tr["tp"]],
    ["Val",   m_va["acc"], m_va["prec"], m_va["recall"], m_va["spec"], m_va["f1"], m_va["auc"], m_va["tn"], m_va["fp"], m_va["fn"], m_va["tp"]],
    ["Test",  m_te["acc"], m_te["prec"], m_te["recall"], m_te["spec"], m_te["f1"], m_te["auc"], m_te["tn"], m_te["fp"], m_te["fn"], m_te["tp"]],
], columns=["Split","Acc","Prec","Recall(Sens)","Spec","F1","AUC","TN","FP","FN","TP"])

print("\n=== METRICS TABLE (Best Fold Model) ===")
try:
    display(summary)
except NameError:
    print(summary)


# ============================================================
# 19) Save model (.pt + .pkl)
# ============================================================

MODEL_PT  = "/content/swin_bestfold_cam.pt"
MODEL_PKL = "/content/swin_bestfold_cam.pkl"

torch.save(best_model.state_dict(), MODEL_PT)

with open(MODEL_PKL, "wb") as f:
    pickle.dump(best_model.cpu(), f)

best_model.to(device)

print("\nSaved model:")
print(MODEL_PT)
print(MODEL_PKL)

!zip -r /content/swin_results_all.zip /content