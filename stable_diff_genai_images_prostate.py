# -*- coding: utf-8 -*-
"""Stable diff genAI images prostate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OD8lj8pp8r1BKtYvDdGXm5HRh1WENtpS
"""





#!rm -rf /content/*

# ============================================================
# PROSTATE MRI AUGMENTATION PIPELINE (TRAIN ONLY) ‚Äî ONE CELL
# MONAI classical augmentation + Stable Diffusion IMG2IMG (low strength)
# Input zips:
#   /content/Cancer.zip
#   /content/Normal.zip
# Output:
#   /content/train_augmented_real.zip
#   /content/train_synthetic_img2img.zip
# ============================================================

!pip -q install "pillow<12" monai tqdm
!pip -q install diffusers transformers accelerate safetensors

import os, zipfile, random, math, shutil
import numpy as np
from PIL import Image
from tqdm import tqdm

import torch
from diffusers import StableDiffusionImg2ImgPipeline

from monai.transforms import (
    Compose, EnsureChannelFirst, Resize, ScaleIntensity,
    RandGaussianNoise, RandAdjustContrast, RandBiasField,
    RandGaussianSmooth, RandHistogramShift
)

# -------------------- CONFIG --------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED)
torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)

CANCER_ZIP = "/content/Cancer.zip"
NORMAL_ZIP = "/content/Normal.zip"

IMG_SIZE = 224  # final size for model training (consistent)
# How many augmented copies per real image (MONAI):
N_MONAI_AUG_PER_REAL = 2

# How many IMG2IMG synthetic images to generate:
N_SYN_CANCER = 35
N_SYN_NORMAL = 25

# IMG2IMG conservative settings:
STRENGTH = 0.12     # VERY LOW = preserve anatomy (0.08‚Äì0.20 range)
GUIDANCE = 3.0      # LOW = avoid hallucination
STEPS = 25

PROMPT = "axial T2-weighted prostate MRI, realistic clinical grayscale appearance"
NEG_PROMPT = "cartoon, illustration, text, watermark, unrealistic anatomy, deformed organ, fake tumor"

# -------------------- OUTPUT PATHS --------------------
ROOT_REAL = "/content/data_real"
REAL_CANCER = os.path.join(ROOT_REAL, "cancer")
REAL_NORMAL = os.path.join(ROOT_REAL, "normal")

ROOT_AUG_REAL = "/content/train_augmented_real"
AUG_CANCER = os.path.join(ROOT_AUG_REAL, "cancer")
AUG_NORMAL = os.path.join(ROOT_AUG_REAL, "normal")

ROOT_SYN = "/content/train_synthetic_img2img"
SYN_CANCER = os.path.join(ROOT_SYN, "cancer")
SYN_NORMAL = os.path.join(ROOT_SYN, "normal")

for p in [REAL_CANCER, REAL_NORMAL, AUG_CANCER, AUG_NORMAL, SYN_CANCER, SYN_NORMAL]:
    os.makedirs(p, exist_ok=True)

# -------------------- UNZIP --------------------
def unzip(zip_path, out_dir):
    if not os.path.exists(zip_path):
        raise FileNotFoundError(f"Zip not found: {zip_path}")
    with zipfile.ZipFile(zip_path, "r") as z:
        z.extractall(out_dir)

# clean old
shutil.rmtree(ROOT_REAL, ignore_errors=True)
shutil.rmtree(ROOT_AUG_REAL, ignore_errors=True)
shutil.rmtree(ROOT_SYN, ignore_errors=True)
for p in [REAL_CANCER, REAL_NORMAL, AUG_CANCER, AUG_NORMAL, SYN_CANCER, SYN_NORMAL]:
    os.makedirs(p, exist_ok=True)

unzip(CANCER_ZIP, REAL_CANCER)
unzip(NORMAL_ZIP, REAL_NORMAL)

# -------------------- RECURSIVE IMAGE SCAN --------------------
def collect_images(root):
    out = []
    for r, _, files in os.walk(root):
        for f in files:
            if f.lower().endswith((".png", ".jpg", ".jpeg")):
                out.append(os.path.join(r, f))
    return sorted(out)

cancer_paths = collect_images(REAL_CANCER)
normal_paths = collect_images(REAL_NORMAL)

print("Cancer images found:", len(cancer_paths))
print("Normal images found:", len(normal_paths))
assert len(cancer_paths) > 0 and len(normal_paths) > 0, "No images found in zips."

# -------------------- HELPERS: LOAD -> GRAYSCALE -> RESIZE --------------------
def load_gray_resized(path, size=IMG_SIZE):
    im = Image.open(path).convert("L")
    im = im.resize((size, size))
    arr = np.array(im).astype(np.float32) / 255.0  # [0,1]
    return arr  # H,W float32

def save_gray(arr01, out_path):
    arr01 = np.clip(arr01, 0, 1)
    img = (arr01 * 255).astype(np.uint8)
    img = img[0]
    Image.fromarray(img).save(out_path)

# -------------------- MONAI AUGMENTATION PIPELINE (SAFE) --------------------
# Works on numpy -> torch -> transforms -> numpy
monai_aug = Compose([
    # EnsureChannelFirst(),  ‚ùå REMOVE THIS
    Resize((IMG_SIZE, IMG_SIZE)),
    ScaleIntensity(),

    RandAdjustContrast(prob=0.7, gamma=(0.85, 1.15)),
    RandHistogramShift(prob=0.5, num_control_points=(5, 10)),
    RandBiasField(prob=0.4, coeff_range=(0.0, 0.25)),
    RandGaussianNoise(prob=0.5, mean=0.0, std=0.01),
    RandGaussianSmooth(prob=0.3, sigma_x=(0.3, 0.9), sigma_y=(0.3, 0.9)),
])

def make_monai_augmented_copies(paths, out_dir, prefix):
    print(f"\nMONAI augmenting {prefix}: {len(paths)} images √ó {N_MONAI_AUG_PER_REAL} copies each")
    idx = 0
    for p in tqdm(paths):
        x = load_gray_resized(p, IMG_SIZE)               # (H,W) in [0,1]
        x_t = torch.from_numpy(x)                        # torch (H,W)
        # save original (normalized/resized) too (optional but useful)
        save_gray(x, os.path.join(out_dir, f"{prefix}_real_{idx:04d}.png"))
        idx += 1

        for k in range(N_MONAI_AUG_PER_REAL):
            y = monai_aug(x_t)                           # (1,H,W)
            y = y.squeeze(0).numpy().astype(np.float32)  # (H,W)
            # y may drift outside [0,1]
            save_gray(y, os.path.join(out_dir, f"{prefix}_monai_{idx:04d}_{k}.png"))
    print("Saved to:", out_dir)

make_monai_augmented_copies(cancer_paths, AUG_CANCER, "cancer")
make_monai_augmented_copies(normal_paths, AUG_NORMAL, "normal")

# -------------------- STABLE DIFFUSION IMG2IMG (CONSERVATIVE) --------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
dtype = torch.float16 if device == "cuda" else torch.float32
print("\nDevice:", device)

pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=dtype,
    safety_checker=None
).to(device)

pipe.enable_attention_slicing()

def generate_img2img(paths, out_dir, n_generate, label):
    print(f"\nIMG2IMG generating {n_generate} synthetic {label} images (strength={STRENGTH})")
    os.makedirs(out_dir, exist_ok=True)
    if len(paths) == 0:
        raise ValueError(f"No source images for {label}")

    # sample with replacement safely
    for i in tqdm(range(n_generate)):
        src_path = random.choice(paths)
        src = Image.open(src_path).convert("L").resize((IMG_SIZE, IMG_SIZE)).convert("RGB")

        out = pipe(
            prompt=PROMPT,
            negative_prompt=NEG_PROMPT,
            image=src,
            strength=STRENGTH,
            guidance_scale=GUIDANCE,
            num_inference_steps=STEPS
        ).images[0]

        # Convert output to grayscale to match your dataset
        out = out.convert("L")
        out.save(os.path.join(out_dir, f"{label}_img2img_{i:03d}.png"))

generate_img2img(cancer_paths, SYN_CANCER, N_SYN_CANCER, "cancer")
generate_img2img(normal_paths, SYN_NORMAL, N_SYN_NORMAL, "normal")

# -------------------- ZIP OUTPUTS FOR DOWNLOAD --------------------
def zip_folder(folder, zip_path):
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as z:
        for r, _, files in os.walk(folder):
            for f in files:
                fp = os.path.join(r, f)
                z.write(fp, arcname=os.path.relpath(fp, folder))

zip_real_aug = "/content/train_augmented_real.zip"
zip_syn = "/content/train_synthetic_img2img.zip"

zip_folder(ROOT_AUG_REAL, zip_real_aug)
zip_folder(ROOT_SYN, zip_syn)

print("\n‚úÖ DONE")
print("Augmented-real cancer:", len(collect_images(AUG_CANCER)))
print("Augmented-real normal:", len(collect_images(AUG_NORMAL)))
print("Synthetic IMG2IMG cancer:", len(collect_images(SYN_CANCER)))
print("Synthetic IMG2IMG normal:", len(collect_images(SYN_NORMAL)))
print("\nDownload these:")
print(zip_real_aug)
print(zip_syn)

!pip -q install scikit-image pytorch-fid

import os, random
import numpy as np
from PIL import Image
from tqdm import tqdm

from skimage.metrics import structural_similarity as ssim
from scipy.stats import wasserstein_distance

def load_gray(path, size=224):
    img = Image.open(path).convert("L").resize((size, size))
    arr = np.array(img).astype(np.float32) / 255.0
    return arr

def collect_images(root):
    out = []
    for r, _, files in os.walk(root):
        for f in files:
            if f.lower().endswith((".png", ".jpg", ".jpeg")):
                out.append(os.path.join(r, f))
    return sorted(out)

def compute_ssim(real_dir, synth_dir, n_pairs=100):
    real_imgs = collect_images(real_dir)
    synth_imgs = collect_images(synth_dir)

    scores = []
    for p in tqdm(random.sample(synth_imgs, min(n_pairs, len(synth_imgs)))):
        syn = load_gray(p)
        real = load_gray(random.choice(real_imgs))
        score = ssim(real, syn, data_range=1.0)
        scores.append(score)

    return np.mean(scores), np.std(scores)

ssim_cancer = compute_ssim(
    "/content/data_real/cancer",
    "/content/train_synthetic_img2img/cancer"
)

ssim_normal = compute_ssim(
    "/content/data_real/normal",
    "/content/train_synthetic_img2img/normal"
)

print("SSIM Cancer (mean ¬± std):", ssim_cancer)
print("SSIM Normal (mean ¬± std):", ssim_normal)

def compute_hist_distance(real_dir, synth_dir, n_pairs=100):
    real_imgs = collect_images(real_dir)
    synth_imgs = collect_images(synth_dir)

    dists = []
    for p in tqdm(random.sample(synth_imgs, min(n_pairs, len(synth_imgs)))):
        syn = load_gray(p).ravel()
        real = load_gray(random.choice(real_imgs)).ravel()
        d = wasserstein_distance(real, syn)
        dists.append(d)

    return np.mean(dists), np.std(dists)

hist_cancer = compute_hist_distance(
    "/content/data_real/cancer",
    "/content/train_synthetic_img2img/cancer"
)

hist_normal = compute_hist_distance(
    "/content/data_real/normal",
    "/content/train_synthetic_img2img/normal"
)

print("Histogram distance Cancer:", hist_cancer)
print("Histogram distance Normal:", hist_normal)

hist_cancer = compute_hist_distance(
    "/content/data_real/cancer",
    "/content/train_synthetic_img2img/cancer"
)

hist_normal = compute_hist_distance(
    "/content/data_real/normal",
    "/content/train_synthetic_img2img/normal"
)

print("Histogram distance Cancer:", hist_cancer)
print("Histogram distance Normal:", hist_normal)

from pytorch_fid import fid_score

def safe_compute_fid(real_dir, synth_dir, max_batch=8):
    n_real = len([f for f in os.listdir(real_dir) if f.lower().endswith((".png",".jpg",".jpeg"))])
    n_syn  = len([f for f in os.listdir(synth_dir) if f.lower().endswith((".png",".jpg",".jpeg"))])

    if n_real < 2 or n_syn < 2:
        print("‚ö†Ô∏è Too few images for reliable FID. Skipping.")
        return None

    batch_size = max(1, min(max_batch, n_real, n_syn))

    print(f"Computing FID with batch_size={batch_size} (real={n_real}, synth={n_syn})")

    fid = fid_score.calculate_fid_given_paths(
        paths=[real_dir, synth_dir],
        batch_size=batch_size,
        device="cuda" if torch.cuda.is_available() else "cpu",
        dims=2048
    )
    return fid

import os
import torch
from pytorch_fid import fid_score

def compute_fid(real_dir, synth_dir):
    paths = [real_dir, synth_dir]
    return fid_score.calculate_fid_given_paths(
        paths=paths,
        batch_size=8,
        device="cuda" if torch.cuda.is_available() else "cpu",
        dims=2048
    )

import zipfile, os

# Real data
REAL_ROOT = "/content/data_real"
os.makedirs(REAL_ROOT, exist_ok=True)

def unzip_if_needed(zip_path, out_dir):
    if not os.path.exists(out_dir) or len(os.listdir(out_dir)) == 0:
        print(f"Unzipping {zip_path} ‚Üí {out_dir}")
        with zipfile.ZipFile(zip_path, 'r') as z:
            z.extractall(out_dir)
    else:
        print(f"{out_dir} already populated")

unzip_if_needed("/content/Cancer.zip", "/content/data_real")
unzip_if_needed("/content/Normal.zip", "/content/data_real")





import os, shutil

def flatten_images(root):
    for sub in ["cancer", "normal"]:
        base = os.path.join(root, sub)
        for r, _, files in os.walk(base):
            for f in files:
                if f.lower().endswith((".png", ".jpg", ".jpeg")):
                    src = os.path.join(r, f)
                    dst = os.path.join(base, f)
                    if src != dst:
                        shutil.move(src, dst)

        # remove empty subfolders
        for r, dirs, _ in os.walk(base, topdown=False):
            for d in dirs:
                p = os.path.join(r, d)
                if len(os.listdir(p)) == 0:
                    os.rmdir(p)

flatten_images("/content/data_real")

def count_images(d):
    return sum(
        f.lower().endswith((".png",".jpg",".jpeg"))
        for f in os.listdir(d)
    )

print("Real cancer images:", count_images("/content/data_real/cancer"))
print("Real normal images:", count_images("/content/data_real/normal"))
print("Synthetic cancer images:", count_images("/content/train_synthetic_img2img/cancer"))
print("Synthetic normal images:", count_images("/content/train_synthetic_img2img/normal"))









from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torch
import os
from pytorch_fid.inception import InceptionV3
import numpy as np

class FIDImageDataset(Dataset):
    def __init__(self, root, size=299):
        self.paths = [
            os.path.join(root, f)
            for f in os.listdir(root)
            if f.lower().endswith((".png", ".jpg", ".jpeg"))
        ]
        self.tf = transforms.Compose([
            transforms.Resize((size, size)),   # ‚úÖ FIX
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, i):
        img = Image.open(self.paths[i]).convert("RGB")
        return self.tf(img)

def compute_fid_safe(real_dir, fake_dir, device="cuda"):
    ds_real = FIDImageDataset(real_dir)
    ds_fake = FIDImageDataset(fake_dir)

    n_real, n_fake = len(ds_real), len(ds_fake)
    print(f"Computing FID with resize=299 | real={n_real} fake={n_fake}")

    if n_real == 0 or n_fake == 0:
        raise ValueError("Empty dataset for FID")

    batch_size = min(8, n_real, n_fake)  # ‚úÖ never zero

    dl_real = DataLoader(ds_real, batch_size=batch_size, shuffle=False, num_workers=2)
    dl_fake = DataLoader(ds_fake, batch_size=batch_size, shuffle=False, num_workers=2)

    dims = 2048
    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]
    model = InceptionV3([block_idx]).to(device).eval()

    def get_acts(dl):
        acts = []
        with torch.no_grad():
            for x in dl:
                x = x.to(device)
                y = model(x)[0]
                y = y.squeeze(-1).squeeze(-1)
                acts.append(y.cpu().numpy())
        return np.concatenate(acts, axis=0)

    act_real = get_acts(dl_real)
    act_fake = get_acts(dl_fake)

    mu1, sigma1 = act_real.mean(0), np.cov(act_real, rowvar=False)
    mu2, sigma2 = act_fake.mean(0), np.cov(act_fake, rowvar=False)

    from scipy.linalg import sqrtm
    covmean = sqrtm(sigma1 @ sigma2)
    if np.iscomplexobj(covmean):
        covmean = covmean.real

    fid = np.sum((mu1 - mu2) ** 2) + np.trace(sigma1 + sigma2 - 2 * covmean)
    return float(fid)

fid_cancer = compute_fid_safe(
    "/content/data_real/cancer",
    "/content/train_synthetic_img2img/cancer"
)

fid_normal = compute_fid_safe(
    "/content/data_real/normal",
    "/content/train_synthetic_img2img/normal"
)

print("FID Cancer:", fid_cancer)
print("FID Normal:", fid_normal)







# ============================================================
# Swin Transformer ‚Äî Real vs Synthetic vs Strong Augmentation
# Paper-safe, leakage-free, MRI-appropriate
# ============================================================

!pip -q install timm umap-learn scikit-learn matplotlib

import os, zipfile, random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torchvision import transforms

from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve
)
import umap
import timm

# -------------------- Reproducibility --------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# -------------------- Paths --------------------
ROOT = "/content/data_all"
REAL_CANCER_ZIP = "/content/Cancer.zip"
REAL_NORMAL_ZIP = "/content/Normal.zip"
SYN_CANCER_ZIP = "/content/cancer_synthetic_generated.zip"
SYN_NORMAL_ZIP = "/content/normal_synthetic_generated.zip"

SYN_ROOT = "/content/synthetic_train_only"
os.makedirs(SYN_ROOT, exist_ok=True)

unzip(SYN_CANCER_ZIP, SYN_ROOT)
unzip(SYN_NORMAL_ZIP, SYN_ROOT)


os.makedirs(ROOT, exist_ok=True)

def unzip(z, out):
    with zipfile.ZipFile(z) as f:
        f.extractall(out)

unzip(REAL_CANCER_ZIP, ROOT)
unzip(REAL_NORMAL_ZIP, ROOT)

def collect_imgs(path):
    imgs=[]
    for r,_,fs in os.walk(path):
        for f in fs:
            if f.lower().endswith((".png",".jpg",".jpeg")):
                imgs.append(os.path.join(r,f))
    return sorted(imgs)

real_cancer = collect_imgs(ROOT + "/Cancer")
real_normal = collect_imgs(ROOT + "/Normal")
syn_cancer  = collect_imgs(SYN_CANCER)
syn_normal  = collect_imgs(SYN_NORMAL)

print("Real cancer:",len(real_cancer),"Real normal:",len(real_normal))
print("Synthetic cancer:",len(syn_cancer),"Synthetic normal:",len(syn_normal))

# -------------------- Dataset --------------------
IMG = 224

tf_eval = transforms.Compose([
    transforms.Grayscale(3),
    transforms.Resize((IMG,IMG)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3,[0.5]*3)
])

tf_safe_aug = transforms.Compose([
    transforms.Grayscale(3),
    transforms.Resize((IMG,IMG)),
    transforms.RandomResizedCrop(IMG, scale=(0.85,1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.3),
    transforms.RandomApply([transforms.ColorJitter(0.2,0.2)], p=0.3),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3,[0.5]*3)
])

class MRI_DS(Dataset):
    def __init__(self,X,y,tf):
        self.X=X; self.y=y; self.tf=tf
    def __len__(self): return len(self.X)
    def __getitem__(self,i):
        img=Image.open(self.X[i]).convert("L")
        return self.tf(img), torch.tensor(self.y[i]).float()

# -------------------- Model --------------------
class SwinBinary(nn.Module):
    def __init__(self,drop=0.5,freeze_ratio=0.75):
        super().__init__()
        self.backbone = timm.create_model(
            "swin_base_patch4_window7_224",
            pretrained=True,
            num_classes=0
        )
        blocks=list(self.backbone.modules())
        for b in blocks[:int(len(blocks)*freeze_ratio)]:
            for p in b.parameters():
                p.requires_grad=False

        self.head=nn.Sequential(
            nn.LayerNorm(self.backbone.num_features),
            nn.Dropout(drop),
            nn.Linear(self.backbone.num_features,1)
        )

    def forward(self,x):
        f=self.backbone(x)
        return self.head(f)

# -------------------- Metrics --------------------
def metrics(y,p):
    y=np.array(y); p=np.array(p)
    yhat=(p>=0.5).astype(int)
    tn,fp,fn,tp=confusion_matrix(y,yhat).ravel()
    return {
        "Acc":accuracy_score(y,yhat),
        "Prec":precision_score(y,yhat,zero_division=0),
        "Recall":recall_score(y,yhat,zero_division=0),
        "Spec":tn/(tn+fp+1e-9),
        "F1":f1_score(y,yhat,zero_division=0),
        "AUC":roc_auc_score(y,p),
        "TN":tn,"FP":fp,"FN":fn,"TP":tp
    }

# -------------------- Train / Eval --------------------
def run_experiment(name,train_X,train_y,val_X,val_y,test_X,test_y,tf_train):
    print(f"\n===== {name} =====")

    ds_tr=MRI_DS(train_X,train_y,tf_train)
    ds_va=MRI_DS(val_X,val_y,tf_eval)
    ds_te=MRI_DS(test_X,test_y,tf_eval)

    counts=np.bincount(train_y.astype(int))
    w=1/(counts+1e-9)
    sampler=WeightedRandomSampler(w[train_y.astype(int)],len(train_y))

    dl_tr=DataLoader(ds_tr,16,sampler=sampler)
    dl_va=DataLoader(ds_va,16)
    dl_te=DataLoader(ds_te,16)

    model=SwinBinary().to(device)
    opt=torch.optim.AdamW(model.parameters(),lr=3e-5,weight_decay=1e-3)
    lossf=nn.BCEWithLogitsLoss(pos_weight=torch.tensor([counts[0]/counts[1]]).to(device))

    hist={"tr":[], "va":[]}

    for ep in range(100):
        model.train()
        for x,y in dl_tr:
            x,y=x.to(device),y.to(device).unsqueeze(1)
            opt.zero_grad()
            loss=lossf(model(x),y)
            loss.backward()
            opt.step()

        def eval_dl(dl):
            model.eval()
            ys,ps=[],[]
            with torch.no_grad():
                for x,y in dl:
                    p=torch.sigmoid(model(x.to(device))).cpu().numpy().ravel()
                    ys+=y.numpy().tolist()
                    ps+=p.tolist()
            return metrics(ys,ps)

        hist["tr"].append(eval_dl(dl_tr)["AUC"])
        hist["va"].append(eval_dl(dl_va)["AUC"])

    m_tr=eval_dl(dl_tr)
    m_va=eval_dl(dl_va)
    m_te=eval_dl(dl_te)

    return m_tr,m_va,m_te,hist,model

# -------------------- Splits (NO leakage) --------------------
X_real = real_cancer + real_normal
y_real = np.array([1]*len(real_cancer)+[0]*len(real_normal))

X_tv,X_test,y_tv,y_test=train_test_split(
    X_real,y_real,test_size=0.2,stratify=y_real,random_state=SEED
)
X_tr,X_va,y_tr,y_va=train_test_split(
    X_tv,y_tv,test_size=0.25,stratify=y_tv,random_state=SEED
)

# -------------------- Section 1: REAL ONLY --------------------
R1 = run_experiment(
    "REAL ONLY",
    X_tr,y_tr,X_va,y_va,X_test,y_test,tf_eval
)

# -------------------- Section 2: REAL + SYN (TRAIN ONLY) --------------------
X_tr_syn = X_tr + syn_cancer + syn_normal
y_tr_syn = np.concatenate([
    y_tr,
    np.ones(len(syn_cancer)),
    np.zeros(len(syn_normal))
])

R2 = run_experiment(
    "REAL + SYNTHETIC (TRAIN ONLY)",
    X_tr_syn,y_tr_syn,X_va,y_va,X_test,y_test,tf_eval
)

# -------------------- Section 3: REAL + STRONG SAFE AUG --------------------
R3 = run_experiment(
    "REAL + MEDICAL SAFE AUG",
    X_tr,y_tr,X_va,y_va,X_test,y_test,tf_safe_aug
)

# -------------------- Final Comparison --------------------
rows=[]
for name,R in zip(
    ["Real","Real+Syn","Real+SafeAug"],
    [R1,R2,R3]
):
    for split,m in zip(["Train","Val","Test"],R[:3]):
        rows.append([name,split]+list(m.values()))

df=pd.DataFrame(
    rows,
    columns=["Method","Split","Acc","Prec","Recall","Spec","F1","AUC","TN","FP","FN","TP"]
)

print("\n=== FINAL COMPARISON TABLE ===")
display(df)





# ============================================================
# SAVE BEST MODEL (for reuse + web app)
# ============================================================

import pickle

# üëâ choose which experiment to deploy
# Options: R1 (Real only), R2 (Real+Synthetic), R3 (Real+SafeAug)
BEST_MODEL = R3[4]   # <-- change if you prefer another experiment

BEST_MODEL.eval()

# ---- 1) Save PyTorch weights (.pt) ----
PT_PATH = "/content/swin_best_model.pt"
torch.save(BEST_MODEL.state_dict(), PT_PATH)

# ---- 2) Save full model as .pkl (for web apps) ----
PKL_PATH = "/content/swin_best_model.pkl"
with open(PKL_PATH, "wb") as f:
    pickle.dump(BEST_MODEL.cpu(), f)

# Move back to GPU if needed later
BEST_MODEL.to(device)

print("‚úÖ Model saved successfully:")
print("PyTorch weights:", PT_PATH)
print("Pickle model   :", PKL_PATH)

!zip -r /content/all_colab_results.zip /content

from google.colab import files
files.download("/content/all_colab_results.zip")